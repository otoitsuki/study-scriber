#!/usr/bin/env python3
"""
éŸ³è¨Šè½‰éŒ„æœå‹™ v2
ä½¿ç”¨å¤§åˆ‡ç‰‡ï¼ˆ10-15ç§’ï¼‰+ ç›´æ¥è½‰æ›çš„æ¶æ§‹ï¼Œé¿å…è¤‡é›œçš„ WebM åˆä½µ
"""

import asyncio
import logging
import subprocess
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, Any, Set
from uuid import UUID
import json
import os

from openai import AzureOpenAI

from ..db.database import get_supabase_client
from app.core.config import settings
from app.core.ffmpeg import detect_audio_format
from app.core.webm_header_repairer import WebMHeaderRepairer
from app.ws.transcript_feed import manager as transcript_manager
from app.services.r2_client import R2Client

logger = logging.getLogger(__name__)

# å…¨åŸŸæ•ˆèƒ½ç›£æ§é–‹é—œ
ENABLE_PERFORMANCE_LOGGING = os.getenv("ENABLE_PERFORMANCE_LOGGING", "true").lower() == "true"

class PerformanceTimer:
    """æ•ˆèƒ½è¨ˆæ™‚å™¨"""

    def __init__(self, operation_name: str):
        self.operation_name = operation_name
        self.start_time = None
        self.end_time = None

    def __enter__(self):
        self.start_time = time.time()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.end_time = time.time()
        duration = self.get_duration()

        if ENABLE_PERFORMANCE_LOGGING:
            if duration > 1.0:  # è¨˜éŒ„è¶…é1ç§’çš„æ“ä½œ
                logger.warning(f"âš ï¸  {self.operation_name} took {duration:.2f}s (slow)")
            else:
                logger.info(f"â±ï¸  {self.operation_name} completed in {duration:.2f}s")

    def get_duration(self) -> float:
        if self.start_time and self.end_time:
            return self.end_time - self.start_time
        return 0.0

# é…ç½®å¸¸æ•¸
CHUNK_DURATION = settings.AUDIO_CHUNK_DURATION_SEC  # å¾é…ç½®è®€å–åˆ‡ç‰‡æ™‚é•·
PROCESSING_TIMEOUT = 30  # è™•ç†è¶…æ™‚ï¼ˆç§’ï¼‰
MAX_RETRIES = 3  # æœ€å¤§é‡è©¦æ¬¡æ•¸

# å…¨åŸŸé›†åˆè¿½è¹¤å·²å»£æ’­ active ç›¸ä½çš„ session
_active_phase_sent: Set[str] = set()

class SimpleAudioTranscriptionService:
    """ç°¡åŒ–çš„éŸ³è¨Šè½‰éŒ„æœå‹™"""

    def __init__(self, azure_client: AzureOpenAI, deployment_name: str):
        self.client = azure_client
        self.deployment_name = deployment_name
        self.processing_tasks: Dict[str, asyncio.Task] = {}

        # WebM æª”é ­ç·©å­˜æ©Ÿåˆ¶
        self._header_cache: Dict[str, bytes] = {}  # session_id -> header_bytes
        self._header_cache_timestamps: Dict[str, float] = {}  # session_id -> timestamp
        self._header_repairer = None  # å»¶é²åˆå§‹åŒ–

        # ç·©å­˜é…ç½®
        self._cache_expiry_seconds = 3600  # 1å°æ™‚
        self._max_cache_sessions = 100  # æœ€å¤š100å€‹session

    def _get_header_repairer(self) -> WebMHeaderRepairer:
        """å»¶é²åˆå§‹åŒ– WebM æª”é ­ä¿®å¾©å™¨"""
        if self._header_repairer is None:
            self._header_repairer = WebMHeaderRepairer()
        return self._header_repairer

    def _extract_and_cache_header(self, session_id: str, chunk_0_data: bytes) -> bool:
        """
        å¾ç¬¬ä¸€å€‹ chunk æå–ä¸¦ç·©å­˜æª”é ­

        Args:
            session_id: æœƒè©± ID
            chunk_0_data: ç¬¬ä¸€å€‹éŸ³è¨Š chunk æ•¸æ“š

        Returns:
            bool: æ˜¯å¦æˆåŠŸæå–ä¸¦ç·©å­˜æª”é ­
        """
        try:
            repairer = self._get_header_repairer()
            result = repairer.extract_header(chunk_0_data)

            if result.success and result.header_data:
                self._header_cache[session_id] = result.header_data
                self._header_cache_timestamps[session_id] = time.time()
                logger.info(f"âœ… [æª”é ­ç·©å­˜] æˆåŠŸæå–ä¸¦ç·©å­˜ session {session_id} çš„æª”é ­ ({len(result.header_data)} bytes)")

                # åŸ·è¡Œç·©å­˜æ¸…ç†
                self._cleanup_expired_cache()
                return True
            else:
                logger.warning(f"âš ï¸ [æª”é ­æå–] Session {session_id} æª”é ­æå–å¤±æ•—: {result.error_message}")
                return False

        except Exception as e:
            logger.error(f"âŒ [æª”é ­æå–] Session {session_id} æª”é ­æå–ç•°å¸¸: {e}")
            return False

    def _get_cached_header(self, session_id: str) -> Optional[bytes]:
        """
        ç²å–ç·©å­˜çš„æª”é ­

        Args:
            session_id: æœƒè©± ID

        Returns:
            Optional[bytes]: ç·©å­˜çš„æª”é ­æ•¸æ“šï¼Œå¦‚æœä¸å­˜åœ¨æˆ–å·²éæœŸå‰‡è¿”å› None
        """
        if session_id not in self._header_cache:
            return None

        # æª¢æŸ¥æ˜¯å¦éæœŸ
        timestamp = self._header_cache_timestamps.get(session_id, 0)
        if time.time() - timestamp > self._cache_expiry_seconds:
            logger.debug(f"ğŸ—‘ï¸ [ç·©å­˜éæœŸ] Session {session_id} æª”é ­ç·©å­˜å·²éæœŸï¼Œè‡ªå‹•æ¸…ç†")
            self._clear_session_cache(session_id)
            return None

        return self._header_cache[session_id]

    def _clear_session_cache(self, session_id: str) -> None:
        """
        æ¸…ç†ç‰¹å®šæœƒè©±çš„ç·©å­˜

        Args:
            session_id: æœƒè©± ID
        """
        self._header_cache.pop(session_id, None)
        self._header_cache_timestamps.pop(session_id, None)
        logger.debug(f"ğŸ—‘ï¸ [ç·©å­˜æ¸…ç†] å·²æ¸…ç† session {session_id} çš„æª”é ­ç·©å­˜")

    def _cleanup_expired_cache(self) -> None:
        """è‡ªå‹•æ¸…ç†éæœŸçš„ç·©å­˜"""
        current_time = time.time()
        expired_sessions = []

        for session_id, timestamp in self._header_cache_timestamps.items():
            if current_time - timestamp > self._cache_expiry_seconds:
                expired_sessions.append(session_id)

        for session_id in expired_sessions:
            self._clear_session_cache(session_id)

        # å¦‚æœç·©å­˜è¶…éæœ€å¤§é™åˆ¶ï¼Œæ¸…ç†æœ€èˆŠçš„æœƒè©±
        if len(self._header_cache) > self._max_cache_sessions:
            # æŒ‰æ™‚é–“æˆ³å‡åºæ’åºï¼Œæœ€èˆŠçš„åœ¨å‰é¢
            sorted_sessions = sorted(
                self._header_cache_timestamps.items(),
                key=lambda x: x[1]  # æŒ‰æ™‚é–“æˆ³æ’åº
            )
            sessions_to_remove = len(self._header_cache) - self._max_cache_sessions
            # ç§»é™¤æœ€èˆŠçš„ sessions
            for session_id, _ in sorted_sessions[:sessions_to_remove]:
                self._clear_session_cache(session_id)
                logger.info(f"ğŸ—‘ï¸ [ç·©å­˜é™åˆ¶] å·²æ¸…ç†æœ€èˆŠçš„ session {session_id} ç·©å­˜")

    async def process_audio_chunk(self, session_id: UUID, chunk_sequence: int, webm_data: bytes) -> bool:
        """
        è™•ç†å–®ä¸€éŸ³è¨Šåˆ‡ç‰‡

        Args:
            session_id: æœƒè©± ID
            chunk_sequence: åˆ‡ç‰‡åºè™Ÿ
            webm_data: WebM éŸ³è¨Šæ•¸æ“š

        Returns:
            bool: è™•ç†æ˜¯å¦æˆåŠŸ
        """
        task_key = f"{session_id}_{chunk_sequence}"

        # é¿å…é‡è¤‡è™•ç†
        if task_key in self.processing_tasks:
            logger.debug(f"Chunk {chunk_sequence} already being processed for session {session_id}")
            return False

        # å»ºç«‹è™•ç†ä»»å‹™
        task = asyncio.create_task(
            self._process_chunk_async(session_id, chunk_sequence, webm_data)
        )
        self.processing_tasks[task_key] = task

        # æ¸…ç†å®Œæˆçš„ä»»å‹™
        task.add_done_callback(lambda t: self.processing_tasks.pop(task_key, None))

        return True

    async def _process_chunk_async(self, session_id: UUID, chunk_sequence: int, webm_data: bytes):
        """éåŒæ­¥è™•ç†éŸ³è¨Šåˆ‡ç‰‡ (WebM ç›´æ¥è½‰éŒ„æ¶æ§‹ v2 + æª”é ­ä¿®å¾©)"""
        try:
            with PerformanceTimer(f"Process chunk {chunk_sequence} for session {session_id}"):
                session_id_str = str(session_id)
                logger.info(f"ğŸš€ [WebM ç›´æ¥è½‰éŒ„] é–‹å§‹è™•ç†éŸ³è¨Šåˆ‡ç‰‡ {chunk_sequence} (session: {session_id}, size: {len(webm_data)} bytes)")

                # æ­¥é©Ÿ 1: é©—è­‰å’Œä¿®å¾© WebM æ•¸æ“šï¼ˆæ•´åˆæª”é ­ä¿®å¾©é‚è¼¯ï¼‰
                processed_webm_data = await self._validate_and_repair_webm_data(session_id, chunk_sequence, webm_data)
                if processed_webm_data is None:
                    logger.error(f"âŒ [é©—è­‰å¤±æ•—] Chunk {chunk_sequence} é©—è­‰å¤±æ•—ï¼Œè·³éè™•ç†")
                    return

                # æ­¥é©Ÿ 3: WebM ç›´æ¥è½‰éŒ„ (ä½¿ç”¨ä¿®å¾©å¾Œçš„æ•¸æ“š)
                logger.info(f"âš¡ [æ¶æ§‹å„ªåŒ–] è·³é FFmpeg è½‰æ›ï¼Œç›´æ¥è½‰éŒ„ WebM (chunk {chunk_sequence})")
                transcript_result = await self._transcribe_audio(processed_webm_data, session_id, chunk_sequence)
                if not transcript_result:
                    logger.error(f"Failed to transcribe WebM chunk {chunk_sequence}")
                    return

                # æ­¥é©Ÿ 4: å„²å­˜ä¸¦æ¨é€çµæœ
                await self._save_and_push_result(session_id, chunk_sequence, transcript_result)

                logger.info(f"âœ… æˆåŠŸè™•ç†éŸ³è¨Šåˆ‡ç‰‡ {chunk_sequence}: '{transcript_result.get('text', '')[:50]}...'")

        except Exception as e:
            logger.error(f"Error processing chunk {chunk_sequence} for session {session_id}: {e}", exc_info=True)

    async def _validate_and_repair_webm_data(self, session_id: UUID, chunk_sequence: int, webm_data: bytes) -> Optional[bytes]:
        """
        é©—è­‰å’Œä¿®å¾© WebM æ•¸æ“šï¼Œé›†æˆæª”é ­å®Œæ•´æ€§æª¢æ¸¬å’Œè‡ªå‹•ä¿®å¾©åŠŸèƒ½

        Args:
            session_id: æœƒè©± ID
            chunk_sequence: åˆ‡ç‰‡åºè™Ÿ
            webm_data: åŸå§‹ WebM éŸ³è¨Šæ•¸æ“š

        Returns:
            Optional[bytes]: ä¿®å¾©å¾Œçš„ WebM æ•¸æ“šï¼Œé©—è­‰å¤±æ•—æ™‚è¿”å› None
        """
        # æ·»åŠ ä¿®å¾©çµ±è¨ˆ
        repair_stats = {
            "validation_time": 0,
            "repair_time": 0,
            "repair_attempted": False,
            "repair_successful": False,
            "original_size": len(webm_data),
            "final_size": 0
        }

        start_time = time.time()

        try:
            # æ­¥é©Ÿ 1: åŸºæœ¬é©—è­‰
            if not webm_data or len(webm_data) < 50:
                logger.warning(f"WebM chunk {chunk_sequence} too small: {len(webm_data) if webm_data else 0} bytes")
                return None

            repair_stats["validation_time"] = (time.time() - start_time) * 1000  # ms
            session_id_str = str(session_id)
            processed_webm_data = webm_data

            # æ­¥é©Ÿ 2: æª”é ­è™•ç†é‚è¼¯
            if chunk_sequence == 0:
                # ç¬¬ä¸€å€‹ chunkï¼šæå–ä¸¦ç·©å­˜æª”é ­
                logger.info(f"ğŸ“¦ [æª”é ­ç·©å­˜] è™•ç†ç¬¬ä¸€å€‹ chunkï¼Œæå–æª”é ­ (session: {session_id_str})")
                extraction_success = self._extract_and_cache_header(session_id_str, webm_data)
                if extraction_success:
                    logger.debug(f"âœ… [æª”é ­æå–] Session {session_id_str} æª”é ­æå–æˆåŠŸ")
                else:
                    logger.warning(f"âš ï¸ [æª”é ­æå–] Session {session_id_str} æª”é ­æå–å¤±æ•—ï¼Œä½†ç¹¼çºŒè™•ç†")

                # ç¬¬ä¸€å€‹ chunk æ‡‰è©²åŒ…å«å®Œæ•´æª”é ­ï¼Œç›´æ¥ä½¿ç”¨
                processed_webm_data = webm_data

            else:
                # å¾ŒçºŒ chunkï¼šæª¢æŸ¥æª”é ­å®Œæ•´æ€§ï¼Œå¿…è¦æ™‚ä¿®å¾©
                logger.info(f"ğŸ”§ [æª”é ­ä¿®å¾©] è™•ç†å¾ŒçºŒ chunk {chunk_sequence} (session: {session_id_str})")
                repair_start = time.time()

                try:
                    repairer = self._get_header_repairer()

                    # æª¢æŸ¥æ˜¯å¦éœ€è¦ä¿®å¾©
                    if not repairer.validate_repaired_chunk(webm_data):
                        logger.info(f"âš ï¸ [æª”é ­ä¿®å¾©] Chunk {chunk_sequence} æª”é ­ä¸å®Œæ•´ï¼Œå˜—è©¦ä¿®å¾©")
                        repair_stats["repair_attempted"] = True

                        # ç²å–ç·©å­˜çš„æª”é ­
                        cached_header = self._get_cached_header(session_id_str)
                        if cached_header:
                            # åŸ·è¡Œæª”é ­ä¿®å¾©
                            repair_result = repairer.repair_chunk(cached_header, webm_data)
                            if repair_result.success and repair_result.repaired_data:
                                processed_webm_data = repair_result.repaired_data
                                repair_stats["repair_successful"] = True
                                logger.info(f"âœ… [æª”é ­ä¿®å¾©] Chunk {chunk_sequence} ä¿®å¾©æˆåŠŸ ({len(processed_webm_data)} bytes)")
                            else:
                                logger.warning(f"âš ï¸ [æª”é ­ä¿®å¾©] Chunk {chunk_sequence} ä¿®å¾©å¤±æ•—: {repair_result.error_message}")
                                processed_webm_data = webm_data  # ä½¿ç”¨åŸå§‹æ•¸æ“š
                        else:
                            logger.warning(f"âš ï¸ [æª”é ­ä¿®å¾©] Session {session_id_str} æ²’æœ‰ç·©å­˜æª”é ­ï¼Œç„¡æ³•ä¿®å¾© chunk {chunk_sequence}")
                            processed_webm_data = webm_data  # ä½¿ç”¨åŸå§‹æ•¸æ“š
                    else:
                        logger.debug(f"âœ… [æª”é ­æª¢æŸ¥] Chunk {chunk_sequence} æª”é ­å®Œæ•´ï¼Œç„¡éœ€ä¿®å¾©")
                        processed_webm_data = webm_data

                except Exception as e:
                    logger.error(f"âŒ [æª”é ­ä¿®å¾©] Chunk {chunk_sequence} ä¿®å¾©éç¨‹ç•°å¸¸: {e}")
                    processed_webm_data = webm_data  # ä½¿ç”¨åŸå§‹æ•¸æ“š
                finally:
                    repair_stats["repair_time"] = (time.time() - repair_start) * 1000  # ms

            # æ­¥é©Ÿ 3: æœ€çµ‚é©—è­‰
            repair_stats["final_size"] = len(processed_webm_data)
            total_time = (time.time() - start_time) * 1000  # ms

            # è¨˜éŒ„æ•ˆèƒ½çµ±è¨ˆ
            if repair_stats["repair_attempted"]:
                status = "æˆåŠŸ" if repair_stats["repair_successful"] else "å¤±æ•—"
                logger.info(f"ğŸ“Š [ä¿®å¾©çµ±è¨ˆ] Chunk {chunk_sequence} ä¿®å¾©{status} - "
                          f"é©—è­‰: {repair_stats['validation_time']:.1f}ms, "
                          f"ä¿®å¾©: {repair_stats['repair_time']:.1f}ms, "
                          f"ç¸½è¨ˆ: {total_time:.1f}ms")
            else:
                logger.debug(f"ğŸ“Š [è™•ç†çµ±è¨ˆ] Chunk {chunk_sequence} ç„¡éœ€ä¿®å¾© - ç¸½è¨ˆ: {total_time:.1f}ms")

            # æ•ˆèƒ½è­¦å‘Š
            if total_time > 50:  # è¶…é50msè­¦å‘Š
                logger.warning(f"âš ï¸ [æ•ˆèƒ½è­¦å‘Š] Chunk {chunk_sequence} è™•ç†æ™‚é–“éé•·: {total_time:.1f}ms")

            return processed_webm_data

        except Exception as e:
            logger.error(f"âŒ [é©—è­‰ä¿®å¾©] Chunk {chunk_sequence} è™•ç†ç•°å¸¸: {e}")
            return webm_data  # é™ç´šä½¿ç”¨åŸå§‹æ•¸æ“š

    async def _convert_webm_to_wav(self, webm_data: bytes, chunk_sequence: int, session_id: UUID) -> Optional[bytes]:
        """
        å°‡ WebM / fMP4 è½‰æ›ç‚º WAV (ä¿ç•™ç”¨æ–¼æœ€çµ‚ä¸‹è¼‰æª”æ¡ˆ)

        æ³¨æ„ï¼šåœ¨ WebM ç›´æ¥è½‰éŒ„æ¶æ§‹ v2 ä¸­ï¼Œæ­¤æ–¹æ³•ä¸å†ç”¨æ–¼å³æ™‚è½‰éŒ„æµç¨‹ï¼Œ
        è€Œæ˜¯ä¿ç•™ä½œç‚ºæœ€çµ‚åŒ¯å‡ºæ™‚ç”Ÿæˆ WAV æª”æ¡ˆçš„å‚™é¸æ–¹æ¡ˆã€‚
        """

        async def _broadcast_error(error_type: str, error_message: str, details: str = None):
            """é€é WebSocket å»£æ’­éŒ¯èª¤è¨Šæ¯åˆ°å‰ç«¯"""
            try:
                from app.ws.transcript_feed import manager as transcript_manager

                # ç”ŸæˆéŸ³æª”è¨ºæ–·è³‡è¨Š
                hex_header = webm_data[:32].hex(' ', 8).upper() if webm_data else "ç„¡æ•¸æ“š"
                audio_format = detect_audio_format(webm_data)

                # æ ¹æ“šæª¢æ¸¬åˆ°çš„æ ¼å¼æä¾›å»ºè­°
                def get_format_suggestion(audio_format: str) -> str:
                    suggestions = {
                        'fmp4': 'å»ºè­°æª¢æŸ¥ç€è¦½å™¨éŒ„éŸ³è¨­å®šï¼Œæˆ–å˜—è©¦ä½¿ç”¨ WebM æ ¼å¼',
                        'mp4': 'å»ºè­°ç¢ºèªéŸ³æª”å®Œæ•´æ€§ï¼Œæˆ–å˜—è©¦ä½¿ç”¨ WebM æ ¼å¼',
                        'webm': 'å»ºè­°æª¢æŸ¥ WebM ç·¨ç¢¼å™¨è¨­å®š',
                        'unknown': 'å»ºè­°æª¢æŸ¥ç€è¦½å™¨æ˜¯å¦æ”¯æ´éŸ³è¨ŠéŒ„è£½ï¼Œæˆ–å˜—è©¦é‡æ–°æ•´ç†é é¢'
                    }
                    return suggestions.get(audio_format, 'å»ºè­°æª¢æŸ¥éŸ³æª”æ ¼å¼æ˜¯å¦æ”¯æ´')

                error_data = {
                    "type": "conversion_error",
                    "error_type": error_type,
                    "message": error_message,
                    "details": details,
                    "session_id": str(session_id),
                    "chunk_sequence": chunk_sequence,
                    "timestamp": datetime.utcnow().isoformat(),
                    "diagnostics": {
                        "detected_format": audio_format,
                        "file_size": len(webm_data) if webm_data else 0,
                        "header_hex": hex_header,
                        "suggestion": get_format_suggestion(audio_format)
                    }
                }
                await transcript_manager.broadcast(
                    json.dumps(error_data),
                    str(session_id)
                )
                logger.info(f"ğŸš¨ [éŒ¯èª¤å»£æ’­] å·²é€šçŸ¥å‰ç«¯è½‰æ›éŒ¯èª¤: {error_type}")
                logger.debug(f"   - æ ¼å¼è¨ºæ–·: {audio_format}, å¤§å°: {len(webm_data) if webm_data else 0} bytes")
                logger.debug(f"   - é ­éƒ¨æ•¸æ“š: {hex_header}")
            except Exception as e:
                logger.error(f"Failed to broadcast error message: {e}")

        try:
            audio_format = detect_audio_format(webm_data)
            logger.info(f"ğŸµ [æ ¼å¼æª¢æ¸¬] æª¢æ¸¬åˆ°éŸ³æª”æ ¼å¼: {audio_format} (chunk {chunk_sequence}, å¤§å°: {len(webm_data)} bytes)")

            with PerformanceTimer(f"{audio_format.upper()} to WAV conversion for chunk {chunk_sequence}"):

                # åŸºæœ¬ FFmpeg åƒæ•¸
                cmd = ['ffmpeg']

                # ä¾ä¾†æºæ ¼å¼æ±ºå®šè¼¸å…¥åƒæ•¸
                if audio_format == 'mp4':
                    # Safari ç”¢å‡ºçš„ fragmented MP4 - è®“ FFmpeg è‡ªå‹•æª¢æ¸¬æ ¼å¼
                    # ä¸æŒ‡å®š -f åƒæ•¸ï¼Œèƒ½æ›´å¥½è™•ç†å„ç¨® MP4 è®Šé«”
                    pass
                elif audio_format == 'webm':
                    cmd += ['-f', 'webm']
                elif audio_format == 'ogg':
                    cmd += ['-f', 'ogg']
                elif audio_format == 'wav':
                    cmd += ['-f', 'wav']

                # é€šç”¨æ——æ¨™ï¼šç”Ÿæˆæ™‚é–“æˆ³è™•ç†ä¸å®Œæ•´æµ
                cmd += ['-fflags', '+genpts', '-i', 'pipe:0', '-ac', '1', '-ar', '16000', '-f', 'wav', '-y', 'pipe:1']

                logger.debug(f"ğŸ”§ [FFmpeg] åŸ·è¡Œå‘½ä»¤: {' '.join(cmd)}")

                process = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdin=asyncio.subprocess.PIPE,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )

                stdout, stderr = await asyncio.wait_for(
                    process.communicate(input=webm_data),
                    timeout=PROCESSING_TIMEOUT
                )

                if process.returncode != 0:
                    error_msg = stderr.decode('utf-8', errors='ignore') if stderr else "Unknown error"
                    logger.error(f"âŒ [FFmpeg éŒ¯èª¤] è½‰æ›å¤±æ•— chunk {chunk_sequence}")
                    logger.error(f"   - æ ¼å¼: {audio_format}")
                    logger.error(f"   - è¿”å›ç¢¼: {process.returncode}")
                    logger.error(f"   - éŒ¯èª¤è¨Šæ¯: {error_msg}")
                    logger.error(f"   - è¼¸å…¥å¤§å°: {len(webm_data)} bytes")

                    # å¢å¼·éŒ¯èª¤åˆ†æï¼Œç‰¹åˆ¥é‡å° fragmented MP4 éŒ¯èª¤
                    if "could not find corresponding trex" in error_msg.lower():
                        error_reason = "Fragmented MP4 æ ¼å¼éŒ¯èª¤ï¼šç¼ºå°‘ Track Extends (trex) ç›’ï¼Œéœ€è¦ä½¿ç”¨ç‰¹æ®Šçš„ movflags åƒæ•¸"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. æª¢æ¸¬åˆ° fragmented MP4 æ ¼å¼ï¼Œå»ºè­°é‡æ–°æ•´ç†é é¢\n"
                            "2. å¦‚æœå•é¡ŒæŒçºŒï¼Œè«‹å˜—è©¦ä½¿ç”¨ä¸åŒç€è¦½å™¨\n"
                            "3. Safari ç”¨æˆ¶å»ºè­°åˆ‡æ›è‡³ Chrome æˆ– Firefox"
                        )
                    elif "trun track id unknown" in error_msg.lower():
                        error_reason = "Fragmented MP4 è¿½è¹¤ ID éŒ¯èª¤ï¼šTrack Run (trun) ç›’ä¸­çš„è»Œé“ ID ç„¡æ³•è­˜åˆ¥"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. é€™æ˜¯ fragmented MP4 ç‰¹æœ‰éŒ¯èª¤\n"
                            "2. å»ºè­°é‡æ–°éŒ„éŸ³æˆ–é‡å•Ÿç€è¦½å™¨\n"
                            "3. è€ƒæ…®é™ä½éŒ„éŸ³å“è³ªè¨­å®š"
                        )
                    elif "Invalid data found when processing input" in error_msg:
                        error_reason = f"éŸ³æª”æ ¼å¼ {audio_format} èˆ‡ FFmpeg ä¸å…¼å®¹ï¼Œå¯èƒ½æ˜¯ç·¨ç¢¼å•é¡Œ"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. æª¢æŸ¥éŸ³æª”æ˜¯å¦å®Œæ•´ä¸‹è¼‰\n"
                            "2. ç¢ºèªç€è¦½å™¨éŒ„éŸ³æ ¼å¼è¨­å®š\n"
                            "3. å˜—è©¦é‡æ–°é–‹å§‹éŒ„éŸ³"
                        )
                    elif "No such file or directory" in error_msg:
                        error_reason = "FFmpeg ç¨‹å¼æœªæ‰¾åˆ°æˆ–é…ç½®éŒ¯èª¤"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. è«‹è¯ç¹«æŠ€è¡“æ”¯æ´\n"
                            "2. é€™æ˜¯ä¼ºæœå™¨é…ç½®å•é¡Œ"
                        )
                    elif "Permission denied" in error_msg:
                        error_reason = "FFmpeg æ¬Šé™ä¸è¶³"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. è«‹è¯ç¹«æŠ€è¡“æ”¯æ´\n"
                            "2. é€™æ˜¯ä¼ºæœå™¨æ¬Šé™å•é¡Œ"
                        )
                    else:
                        error_reason = f"FFmpeg è™•ç† {audio_format} æ ¼å¼æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. å˜—è©¦é‡æ–°éŒ„éŸ³\n"
                            "2. æª¢æŸ¥ç¶²è·¯é€£ç·šæ˜¯å¦ç©©å®š\n"
                            "3. å¦‚æœå•é¡ŒæŒçºŒï¼Œè«‹è¯ç¹«æŠ€è¡“æ”¯æ´"
                        )

                    # è¨˜éŒ„è©³ç´°è¨ºæ–·è³‡è¨Š
                    logger.error(f"   - è¨ºæ–·çµæœ: {error_reason}")
                    logger.error(f"   - å»ºè­°æ–¹æ¡ˆ: {detailed_suggestion}")

                    await _broadcast_error("ffmpeg_conversion_failed", error_reason, detailed_suggestion)
                    return None

                if not stdout or len(stdout) < 100:
                    error_msg = f"FFmpeg ç”¢ç”Ÿçš„ WAV æ•¸æ“šä¸è¶³: {len(stdout) if stdout else 0} bytes"
                    logger.error(f"âŒ [FFmpeg è­¦å‘Š] {error_msg}")
                    await _broadcast_error("insufficient_output", "è½‰æ›å¾Œçš„éŸ³æª”æ•¸æ“šä¸è¶³ï¼Œå¯èƒ½æ˜¯éœéŸ³æˆ–æå£", error_msg)
                    return None

                logger.info(f"âœ… [FFmpeg æˆåŠŸ] {audio_format.upper()} ({len(webm_data)} bytes) â†’ WAV ({len(stdout)} bytes)")
                return stdout

        except asyncio.TimeoutError:
            error_msg = f"FFmpeg è½‰æ›è¶…æ™‚ (>{PROCESSING_TIMEOUT}ç§’)"
            logger.error(f"â° [FFmpeg è¶…æ™‚] {error_msg}")
            await _broadcast_error("conversion_timeout", "éŸ³æª”è½‰æ›è™•ç†æ™‚é–“éé•·", error_msg)
            return None
        except Exception as e:
            error_msg = f"FFmpeg è½‰æ›ç•°å¸¸: {str(e)}"
            logger.error(f"ğŸ’¥ [FFmpeg ç•°å¸¸] {error_msg}")
            await _broadcast_error("conversion_exception", "éŸ³æª”è½‰æ›éç¨‹ä¸­ç™¼ç”Ÿç•°å¸¸éŒ¯èª¤", error_msg)
            return None

    async def _transcribe_audio(self, webm_data: bytes, session_id: UUID, chunk_sequence: int) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨ Azure OpenAI Whisper ç›´æ¥è½‰éŒ„ WebM éŸ³è¨Š (æ¶æ§‹å„ªåŒ– v2)"""
        try:
            with PerformanceTimer(f"Whisper WebM transcription for chunk {chunk_sequence}"):
                # å»ºç«‹ WebM æ ¼å¼è‡¨æ™‚æª”æ¡ˆ (ç„¡éœ€ FFmpeg è½‰æ›)
                with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as temp_file:
                    temp_file.write(webm_data)
                    temp_file.flush()

                    try:
                        # ç›´æ¥ä½¿ç”¨ WebM æª”æ¡ˆå‘¼å« Whisper API
                        with open(temp_file.name, 'rb') as audio_file:
                            transcript = self.client.audio.transcriptions.create(
                                model=self.deployment_name,
                                file=audio_file,
                                language="zh",
                                response_format="text"
                            )

                        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                        Path(temp_file.name).unlink(missing_ok=True)

                        if not transcript or not transcript.strip():
                            logger.debug(f"Empty transcript for chunk {chunk_sequence}")
                            return None

                        logger.info(f"ğŸ¯ [WebM ç›´æ¥è½‰éŒ„] æˆåŠŸè™•ç† chunk {chunk_sequence} (æ ¼å¼: WebM â†’ Whisper API)")

                        return {
                            'text': transcript.strip(),
                            'chunk_sequence': chunk_sequence,
                            'session_id': str(session_id),
                            'timestamp': datetime.utcnow().isoformat(),
                            'language': 'zh-TW',
                            'duration': CHUNK_DURATION
                        }

                    finally:
                        # ç¢ºä¿æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                        Path(temp_file.name).unlink(missing_ok=True)

        except Exception as e:
            logger.error(f"WebM direct transcription failed for chunk {chunk_sequence}: {e}")
            # å»£æ’­ Whisper API éŒ¯èª¤åˆ°å‰ç«¯
            await self._broadcast_transcription_error(session_id, chunk_sequence, "whisper_api_error", f"Azure OpenAI Whisper WebM è½‰éŒ„å¤±æ•—: {str(e)}")
            return None

    async def _save_and_push_result(self, session_id: UUID, chunk_sequence: int, transcript_result: Dict[str, Any]):
        """å„²å­˜è½‰éŒ„çµæœä¸¦æ¨é€åˆ°å‰ç«¯"""
        try:
            # å„²å­˜åˆ°è³‡æ–™åº«
            supabase = get_supabase_client()

            segment_data = {
                "session_id": str(session_id),
                "chunk_sequence": chunk_sequence,
                "text": transcript_result['text'],
                "start_time": chunk_sequence * CHUNK_DURATION,
                "end_time": (chunk_sequence + 1) * CHUNK_DURATION,
                "confidence": 1.0,
                "language": transcript_result.get('language', 'zh-TW'),
                "created_at": transcript_result['timestamp']
            }

            response = supabase.table("transcript_segments").insert(segment_data).execute()

            if response.data:
                segment_id = response.data[0]['id']
                logger.debug(f"Saved transcript segment {segment_id} for chunk {chunk_sequence}")

                # é€é WebSocket å»£æ’­è½‰éŒ„çµæœ
                # è‹¥å°šæœªå»£æ’­ active ç›¸ä½ï¼Œå…ˆé€å‡º
                if str(session_id) not in _active_phase_sent:
                    logger.info(f"ğŸš€ [è½‰éŒ„æ¨é€] é¦–æ¬¡å»£æ’­ active ç›¸ä½åˆ° session {session_id}")
                    await transcript_manager.broadcast(
                        json.dumps({"phase": "active"}),
                        str(session_id)
                    )
                    _active_phase_sent.add(str(session_id))
                    logger.info(f"âœ… [è½‰éŒ„æ¨é€] Active ç›¸ä½å»£æ’­å®Œæˆ for session {session_id}")

                # æ§‹å»ºé€å­—ç¨¿ç‰‡æ®µè¨Šæ¯
                transcript_message = {
                    "type": "transcript_segment",
                    "session_id": str(session_id),
                    "segment_id": segment_id,
                    "text": transcript_result['text'],
                    "chunk_sequence": chunk_sequence,
                    "start_sequence": chunk_sequence,  # æ·»åŠ  start_sequence æ¬„ä½
                    "start_time": segment_data['start_time'],
                    "end_time": segment_data['end_time'],
                    "confidence": segment_data['confidence'],
                    "timestamp": segment_data['created_at']
                }

                logger.info(f"ğŸ“¡ [è½‰éŒ„æ¨é€] å»£æ’­é€å­—ç¨¿ç‰‡æ®µåˆ° session {session_id}:")
                logger.info(f"   - æ–‡å­—: '{transcript_result['text'][:50]}{'...' if len(transcript_result['text']) > 50 else ''}'")
                logger.info(f"   - åºè™Ÿ: {chunk_sequence}")
                logger.info(f"   - æ™‚é–“: {segment_data['start_time']}s - {segment_data['end_time']}s")

                await transcript_manager.broadcast(
                    json.dumps(transcript_message),
                    str(session_id)
                )

                logger.info(f"âœ… [è½‰éŒ„æ¨é€] é€å­—ç¨¿ç‰‡æ®µå»£æ’­å®Œæˆ for session {session_id}")

                # å»£æ’­è½‰éŒ„å®Œæˆæ¶ˆæ¯
                logger.info(f"å»£æ’­è½‰éŒ„å®Œæˆè¨Šæ¯åˆ° session {session_id}")
                await transcript_manager.broadcast(
                    json.dumps({
                        "type": "transcript_complete",
                        "session_id": str(session_id),
                        "message": "Transcription completed for the batch."
                    }),
                    str(session_id)
                )
                logger.info(f"è½‰éŒ„ä»»å‹™å®Œæˆ for session: {session_id}, chunk: {chunk_sequence}")

        except Exception as e:
            logger.error(f"Failed to save/push transcript for chunk {chunk_sequence}: {e}")
            # å»£æ’­è½‰éŒ„å¤±æ•—éŒ¯èª¤åˆ°å‰ç«¯
            await self._broadcast_transcription_error(session_id, chunk_sequence, "database_error", f"è³‡æ–™åº«æ“ä½œå¤±æ•—: {str(e)}")

    async def _broadcast_transcription_error(self, session_id: UUID, chunk_sequence: int, error_type: str, error_message: str):
        """å»£æ’­è½‰éŒ„éŒ¯èª¤åˆ°å‰ç«¯"""
        try:
            from app.ws.transcript_feed import manager as transcript_manager
            error_data = {
                "type": "transcription_error",
                "error_type": error_type,
                "message": error_message,
                "session_id": str(session_id),
                "chunk_sequence": chunk_sequence,
                "timestamp": datetime.utcnow().isoformat()
            }
            await transcript_manager.broadcast(
                json.dumps(error_data),
                str(session_id)
            )
            logger.info(f"ğŸš¨ [è½‰éŒ„éŒ¯èª¤å»£æ’­] å·²é€šçŸ¥å‰ç«¯è½‰éŒ„éŒ¯èª¤: {error_type}")
        except Exception as e:
            logger.error(f"Failed to broadcast transcription error: {e}")

    # TODO: åœ¨æ­¤è™•å¯¦ç¾æ›´å„ªé›…çš„é—œé–‰é‚è¼¯
    logger.info("Transcription service is shutting down...")

# ----------------------
# å…¼å®¹èˆŠæ¸¬è©¦çš„å·¥å» å‡½å¼èˆ‡å…¨åŸŸè®Šæ•¸
# ----------------------

_transcription_service_v2: Optional[SimpleAudioTranscriptionService] = None


def get_azure_openai_client() -> Optional[AzureOpenAI]:
    """æ ¹æ“šç’°å¢ƒè®Šæ•¸å»ºç«‹ AzureOpenAI ç”¨æˆ¶ç«¯ï¼Œç¼ºå€¼æ™‚å›å‚³ Noneã€‚"""
    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    if not api_key or not endpoint:
        return None
    # ä½¿ç”¨é è¨­ API ç‰ˆæœ¬å³å¯
    return AzureOpenAI(api_key=api_key, api_version="2024-06-01", azure_endpoint=endpoint)


def get_whisper_deployment_name() -> Optional[str]:
    """å–å¾— Whisper éƒ¨ç½²åç¨±ï¼Œç’°å¢ƒè®Šæ•¸ç¼ºå€¼æ™‚å›å‚³ Noneã€‚"""
    return os.getenv("WHISPER_DEPLOYMENT_NAME")


async def initialize_transcription_service_v2() -> Optional[SimpleAudioTranscriptionService]:
    """åˆå§‹åŒ–ä¸¦å¿«å– SimpleAudioTranscriptionService å¯¦ä¾‹ã€‚è‹¥è¨­å®šä¸è¶³å‰‡å›å‚³ Noneã€‚"""
    global _transcription_service_v2
    if _transcription_service_v2 is not None:
        return _transcription_service_v2

    client = get_azure_openai_client()
    deployment = get_whisper_deployment_name()
    if not client or not deployment:
        logger.warning("Azure OpenAI è¨­å®šä¸è¶³ï¼Œç„¡æ³•åˆå§‹åŒ–è½‰éŒ„æœå‹™ v2")
        return None

    _transcription_service_v2 = SimpleAudioTranscriptionService(client, deployment)
    logger.info("âœ… Transcription service v2 initialized")
    return _transcription_service_v2


def cleanup_transcription_service_v2():
    """æ¸…ç†å…¨åŸŸè½‰éŒ„æœå‹™å¯¦ä¾‹ã€‚"""
    global _transcription_service_v2
    _transcription_service_v2 = None
