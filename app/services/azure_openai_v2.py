#!/usr/bin/env python3
"""
éŸ³è¨Šè½‰éŒ„æœå‹™ v2
ä½¿ç”¨å¤§åˆ‡ç‰‡ï¼ˆ10-15ç§’ï¼‰+ ç›´æ¥è½‰æ›çš„æ¶æ§‹ï¼Œé¿å…è¤‡é›œçš„ WebM åˆä½µ
"""

import asyncio
import logging
import subprocess
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, Any, Set
from uuid import UUID
import json
import os

from openai import AzureOpenAI

from ..db.database import get_supabase_client
from app.core.config import settings
from app.core.ffmpeg import detect_audio_format
from app.ws.transcript_feed import manager as transcript_manager
from app.services.r2_client import R2Client

logger = logging.getLogger(__name__)

# å…¨åŸŸæ•ˆèƒ½ç›£æ§é–‹é—œ
ENABLE_PERFORMANCE_LOGGING = os.getenv("ENABLE_PERFORMANCE_LOGGING", "true").lower() == "true"

class PerformanceTimer:
    """æ•ˆèƒ½è¨ˆæ™‚å™¨"""

    def __init__(self, operation_name: str):
        self.operation_name = operation_name
        self.start_time = None
        self.end_time = None

    def __enter__(self):
        self.start_time = time.time()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.end_time = time.time()
        duration = self.get_duration()

        if ENABLE_PERFORMANCE_LOGGING:
            if duration > 1.0:  # è¨˜éŒ„è¶…é1ç§’çš„æ“ä½œ
                logger.warning(f"âš ï¸  {self.operation_name} took {duration:.2f}s (slow)")
            else:
                logger.info(f"â±ï¸  {self.operation_name} completed in {duration:.2f}s")

    def get_duration(self) -> float:
        if self.start_time and self.end_time:
            return self.end_time - self.start_time
        return 0.0

# é…ç½®å¸¸æ•¸
CHUNK_DURATION = 12  # 12 ç§’åˆ‡ç‰‡
PROCESSING_TIMEOUT = 30  # è™•ç†è¶…æ™‚ï¼ˆç§’ï¼‰
MAX_RETRIES = 3  # æœ€å¤§é‡è©¦æ¬¡æ•¸

# å…¨åŸŸé›†åˆè¿½è¹¤å·²å»£æ’­ active ç›¸ä½çš„ session
_active_phase_sent: Set[str] = set()

class SimpleAudioTranscriptionService:
    """ç°¡åŒ–çš„éŸ³è¨Šè½‰éŒ„æœå‹™"""

    def __init__(self, azure_client: AzureOpenAI, deployment_name: str):
        self.client = azure_client
        self.deployment_name = deployment_name
        self.processing_tasks: Dict[str, asyncio.Task] = {}

    async def process_audio_chunk(self, session_id: UUID, chunk_sequence: int, webm_data: bytes) -> bool:
        """
        è™•ç†å–®ä¸€éŸ³è¨Šåˆ‡ç‰‡

        Args:
            session_id: æœƒè©± ID
            chunk_sequence: åˆ‡ç‰‡åºè™Ÿ
            webm_data: WebM éŸ³è¨Šæ•¸æ“š

        Returns:
            bool: è™•ç†æ˜¯å¦æˆåŠŸ
        """
        task_key = f"{session_id}_{chunk_sequence}"

        # é¿å…é‡è¤‡è™•ç†
        if task_key in self.processing_tasks:
            logger.debug(f"Chunk {chunk_sequence} already being processed for session {session_id}")
            return False

        # å»ºç«‹è™•ç†ä»»å‹™
        task = asyncio.create_task(
            self._process_chunk_async(session_id, chunk_sequence, webm_data)
        )
        self.processing_tasks[task_key] = task

        # æ¸…ç†å®Œæˆçš„ä»»å‹™
        task.add_done_callback(lambda t: self.processing_tasks.pop(task_key, None))

        return True

    async def _process_chunk_async(self, session_id: UUID, chunk_sequence: int, webm_data: bytes):
        """éåŒæ­¥è™•ç†éŸ³è¨Šåˆ‡ç‰‡"""
        try:
            with PerformanceTimer(f"Process chunk {chunk_sequence} for session {session_id}"):
                logger.info(f"ğŸµ é–‹å§‹è™•ç†éŸ³è¨Šåˆ‡ç‰‡ {chunk_sequence} (session: {session_id}, size: {len(webm_data)} bytes)")

                # æ­¥é©Ÿ 1: é©—è­‰ WebM æ•¸æ“š
                if not self._validate_webm_data(webm_data, chunk_sequence):
                    return

                # æ­¥é©Ÿ 2: WebM â†’ WAV è½‰æ›
                wav_data = await self._convert_webm_to_wav(webm_data, chunk_sequence, session_id)
                if not wav_data:
                    logger.error(f"Failed to convert WebM to WAV for chunk {chunk_sequence}")
                    # éŒ¯èª¤å·²åœ¨ _convert_webm_to_wav ä¸­å»£æ’­ï¼Œé€™è£¡åªéœ€è¦è¿”å›
                    return

                # æ­¥é©Ÿ 3: Whisper è½‰éŒ„
                transcript_result = await self._transcribe_audio(wav_data, session_id, chunk_sequence)
                if not transcript_result:
                    logger.error(f"Failed to transcribe chunk {chunk_sequence}")
                    return

                # æ­¥é©Ÿ 4: å„²å­˜ä¸¦æ¨é€çµæœ
                await self._save_and_push_result(session_id, chunk_sequence, transcript_result)

                logger.info(f"âœ… æˆåŠŸè™•ç†éŸ³è¨Šåˆ‡ç‰‡ {chunk_sequence}: '{transcript_result.get('text', '')[:50]}...'")

        except Exception as e:
            logger.error(f"Error processing chunk {chunk_sequence} for session {session_id}: {e}", exc_info=True)

    def _validate_webm_data(self, webm_data: bytes, chunk_sequence: int) -> bool:
        """é©—è­‰ WebM æ•¸æ“š - ç°¡åŒ–ç‰ˆæœ¬ï¼Œä¿¡ä»»ç€è¦½å™¨ç”¢ç”Ÿçš„è³‡æ–™"""
        if not webm_data or len(webm_data) < 50:
            logger.warning(f"WebM chunk {chunk_sequence} too small: {len(webm_data) if webm_data else 0} bytes")
            return False

        # ç§»é™¤ EBML æ¨™é ­æª¢æŸ¥ï¼Œä¿¡ä»» MediaRecorder ç”¢ç”Ÿçš„è³‡æ–™
        # FFmpeg æœƒç”¨ -fflags +genpts è™•ç†ä¸å®Œæ•´çš„æµå¼è³‡æ–™
        return True

    async def _convert_webm_to_wav(self, webm_data: bytes, chunk_sequence: int, session_id: UUID) -> Optional[bytes]:
        """å°‡ WebM / fMP4 è½‰æ›ç‚º WAVï¼Œè‡ªå‹•è¾¨è­˜ä¾†æºæ ¼å¼ï¼Œå¢å¼·éŒ¯èª¤è™•ç†å’Œå›å ±æ©Ÿåˆ¶"""

        async def _broadcast_error(error_type: str, error_message: str, details: str = None):
            """é€é WebSocket å»£æ’­éŒ¯èª¤è¨Šæ¯åˆ°å‰ç«¯"""
            try:
                from app.ws.transcript_feed import manager as transcript_manager

                # ç”ŸæˆéŸ³æª”è¨ºæ–·è³‡è¨Š
                hex_header = webm_data[:32].hex(' ', 8).upper() if webm_data else "ç„¡æ•¸æ“š"
                audio_format = detect_audio_format(webm_data)

                # æ ¹æ“šæª¢æ¸¬åˆ°çš„æ ¼å¼æä¾›å»ºè­°
                def get_format_suggestion(audio_format: str) -> str:
                    suggestions = {
                        'fmp4': 'å»ºè­°æª¢æŸ¥ç€è¦½å™¨éŒ„éŸ³è¨­å®šï¼Œæˆ–å˜—è©¦ä½¿ç”¨ WebM æ ¼å¼',
                        'mp4': 'å»ºè­°ç¢ºèªéŸ³æª”å®Œæ•´æ€§ï¼Œæˆ–å˜—è©¦ä½¿ç”¨ WebM æ ¼å¼',
                        'webm': 'å»ºè­°æª¢æŸ¥ WebM ç·¨ç¢¼å™¨è¨­å®š',
                        'unknown': 'å»ºè­°æª¢æŸ¥ç€è¦½å™¨æ˜¯å¦æ”¯æ´éŸ³è¨ŠéŒ„è£½ï¼Œæˆ–å˜—è©¦é‡æ–°æ•´ç†é é¢'
                    }
                    return suggestions.get(audio_format, 'å»ºè­°æª¢æŸ¥éŸ³æª”æ ¼å¼æ˜¯å¦æ”¯æ´')

                error_data = {
                    "type": "conversion_error",
                    "error_type": error_type,
                    "message": error_message,
                    "details": details,
                    "session_id": str(session_id),
                    "chunk_sequence": chunk_sequence,
                    "timestamp": datetime.utcnow().isoformat(),
                    "diagnostics": {
                        "detected_format": audio_format,
                        "file_size": len(webm_data) if webm_data else 0,
                        "header_hex": hex_header,
                        "suggestion": get_format_suggestion(audio_format)
                    }
                }
                await transcript_manager.broadcast(
                    json.dumps(error_data),
                    str(session_id)
                )
                logger.info(f"ğŸš¨ [éŒ¯èª¤å»£æ’­] å·²é€šçŸ¥å‰ç«¯è½‰æ›éŒ¯èª¤: {error_type}")
                logger.debug(f"   - æ ¼å¼è¨ºæ–·: {audio_format}, å¤§å°: {len(webm_data) if webm_data else 0} bytes")
                logger.debug(f"   - é ­éƒ¨æ•¸æ“š: {hex_header}")
            except Exception as e:
                logger.error(f"Failed to broadcast error message: {e}")

        try:
            audio_format = detect_audio_format(webm_data)
            logger.info(f"ğŸµ [æ ¼å¼æª¢æ¸¬] æª¢æ¸¬åˆ°éŸ³æª”æ ¼å¼: {audio_format} (chunk {chunk_sequence}, å¤§å°: {len(webm_data)} bytes)")

            with PerformanceTimer(f"{audio_format.upper()} to WAV conversion for chunk {chunk_sequence}"):

                # åŸºæœ¬ FFmpeg åƒæ•¸
                cmd = ['ffmpeg']

                # ä¾ä¾†æºæ ¼å¼æ±ºå®šè¼¸å…¥åƒæ•¸
                if audio_format == 'mp4':
                    # Safari ç”¢å‡ºçš„ fragmented MP4 - è®“ FFmpeg è‡ªå‹•æª¢æ¸¬æ ¼å¼
                    # ä¸æŒ‡å®š -f åƒæ•¸ï¼Œèƒ½æ›´å¥½è™•ç†å„ç¨® MP4 è®Šé«”
                    pass
                elif audio_format == 'webm':
                    cmd += ['-f', 'webm']
                elif audio_format == 'ogg':
                    cmd += ['-f', 'ogg']
                elif audio_format == 'wav':
                    cmd += ['-f', 'wav']

                # é€šç”¨æ——æ¨™ï¼šç”Ÿæˆæ™‚é–“æˆ³è™•ç†ä¸å®Œæ•´æµ
                cmd += ['-fflags', '+genpts', '-i', 'pipe:0', '-ac', '1', '-ar', '16000', '-f', 'wav', '-y', 'pipe:1']

                logger.debug(f"ğŸ”§ [FFmpeg] åŸ·è¡Œå‘½ä»¤: {' '.join(cmd)}")

                process = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdin=asyncio.subprocess.PIPE,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )

                stdout, stderr = await asyncio.wait_for(
                    process.communicate(input=webm_data),
                    timeout=PROCESSING_TIMEOUT
                )

                if process.returncode != 0:
                    error_msg = stderr.decode('utf-8', errors='ignore') if stderr else "Unknown error"
                    logger.error(f"âŒ [FFmpeg éŒ¯èª¤] è½‰æ›å¤±æ•— chunk {chunk_sequence}")
                    logger.error(f"   - æ ¼å¼: {audio_format}")
                    logger.error(f"   - è¿”å›ç¢¼: {process.returncode}")
                    logger.error(f"   - éŒ¯èª¤è¨Šæ¯: {error_msg}")
                    logger.error(f"   - è¼¸å…¥å¤§å°: {len(webm_data)} bytes")

                    # å¢å¼·éŒ¯èª¤åˆ†æï¼Œç‰¹åˆ¥é‡å° fragmented MP4 éŒ¯èª¤
                    if "could not find corresponding trex" in error_msg.lower():
                        error_reason = "Fragmented MP4 æ ¼å¼éŒ¯èª¤ï¼šç¼ºå°‘ Track Extends (trex) ç›’ï¼Œéœ€è¦ä½¿ç”¨ç‰¹æ®Šçš„ movflags åƒæ•¸"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. æª¢æ¸¬åˆ° fragmented MP4 æ ¼å¼ï¼Œå»ºè­°é‡æ–°æ•´ç†é é¢\n"
                            "2. å¦‚æœå•é¡ŒæŒçºŒï¼Œè«‹å˜—è©¦ä½¿ç”¨ä¸åŒç€è¦½å™¨\n"
                            "3. Safari ç”¨æˆ¶å»ºè­°åˆ‡æ›è‡³ Chrome æˆ– Firefox"
                        )
                    elif "trun track id unknown" in error_msg.lower():
                        error_reason = "Fragmented MP4 è¿½è¹¤ ID éŒ¯èª¤ï¼šTrack Run (trun) ç›’ä¸­çš„è»Œé“ ID ç„¡æ³•è­˜åˆ¥"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. é€™æ˜¯ fragmented MP4 ç‰¹æœ‰éŒ¯èª¤\n"
                            "2. å»ºè­°é‡æ–°éŒ„éŸ³æˆ–é‡å•Ÿç€è¦½å™¨\n"
                            "3. è€ƒæ…®é™ä½éŒ„éŸ³å“è³ªè¨­å®š"
                        )
                    elif "Invalid data found when processing input" in error_msg:
                        error_reason = f"éŸ³æª”æ ¼å¼ {audio_format} èˆ‡ FFmpeg ä¸å…¼å®¹ï¼Œå¯èƒ½æ˜¯ç·¨ç¢¼å•é¡Œ"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. æª¢æŸ¥éŸ³æª”æ˜¯å¦å®Œæ•´ä¸‹è¼‰\n"
                            "2. ç¢ºèªç€è¦½å™¨éŒ„éŸ³æ ¼å¼è¨­å®š\n"
                            "3. å˜—è©¦é‡æ–°é–‹å§‹éŒ„éŸ³"
                        )
                    elif "No such file or directory" in error_msg:
                        error_reason = "FFmpeg ç¨‹å¼æœªæ‰¾åˆ°æˆ–é…ç½®éŒ¯èª¤"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. è«‹è¯ç¹«æŠ€è¡“æ”¯æ´\n"
                            "2. é€™æ˜¯ä¼ºæœå™¨é…ç½®å•é¡Œ"
                        )
                    elif "Permission denied" in error_msg:
                        error_reason = "FFmpeg æ¬Šé™ä¸è¶³"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. è«‹è¯ç¹«æŠ€è¡“æ”¯æ´\n"
                            "2. é€™æ˜¯ä¼ºæœå™¨æ¬Šé™å•é¡Œ"
                        )
                    else:
                        error_reason = f"FFmpeg è™•ç† {audio_format} æ ¼å¼æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤"
                        detailed_suggestion = (
                            "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\n"
                            "1. å˜—è©¦é‡æ–°éŒ„éŸ³\n"
                            "2. æª¢æŸ¥ç¶²è·¯é€£ç·šæ˜¯å¦ç©©å®š\n"
                            "3. å¦‚æœå•é¡ŒæŒçºŒï¼Œè«‹è¯ç¹«æŠ€è¡“æ”¯æ´"
                        )

                    # è¨˜éŒ„è©³ç´°è¨ºæ–·è³‡è¨Š
                    logger.error(f"   - è¨ºæ–·çµæœ: {error_reason}")
                    logger.error(f"   - å»ºè­°æ–¹æ¡ˆ: {detailed_suggestion}")

                    await _broadcast_error("ffmpeg_conversion_failed", error_reason, detailed_suggestion)
                    return None

                if not stdout or len(stdout) < 100:
                    error_msg = f"FFmpeg ç”¢ç”Ÿçš„ WAV æ•¸æ“šä¸è¶³: {len(stdout) if stdout else 0} bytes"
                    logger.error(f"âŒ [FFmpeg è­¦å‘Š] {error_msg}")
                    await _broadcast_error("insufficient_output", "è½‰æ›å¾Œçš„éŸ³æª”æ•¸æ“šä¸è¶³ï¼Œå¯èƒ½æ˜¯éœéŸ³æˆ–æå£", error_msg)
                    return None

                logger.info(f"âœ… [FFmpeg æˆåŠŸ] {audio_format.upper()} ({len(webm_data)} bytes) â†’ WAV ({len(stdout)} bytes)")
                return stdout

        except asyncio.TimeoutError:
            error_msg = f"FFmpeg è½‰æ›è¶…æ™‚ (>{PROCESSING_TIMEOUT}ç§’)"
            logger.error(f"â° [FFmpeg è¶…æ™‚] {error_msg}")
            await _broadcast_error("conversion_timeout", "éŸ³æª”è½‰æ›è™•ç†æ™‚é–“éé•·", error_msg)
            return None
        except Exception as e:
            error_msg = f"FFmpeg è½‰æ›ç•°å¸¸: {str(e)}"
            logger.error(f"ğŸ’¥ [FFmpeg ç•°å¸¸] {error_msg}")
            await _broadcast_error("conversion_exception", "éŸ³æª”è½‰æ›éç¨‹ä¸­ç™¼ç”Ÿç•°å¸¸éŒ¯èª¤", error_msg)
            return None

    async def _transcribe_audio(self, wav_data: bytes, session_id: UUID, chunk_sequence: int) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨ Azure OpenAI Whisper è½‰éŒ„éŸ³è¨Š"""
        try:
            with PerformanceTimer(f"Whisper transcription for chunk {chunk_sequence}"):
                # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                    temp_file.write(wav_data)
                    temp_file.flush()

                    try:
                        # Whisper API å‘¼å«
                        with open(temp_file.name, 'rb') as audio_file:
                            transcript = self.client.audio.transcriptions.create(
                                model=self.deployment_name,
                                file=audio_file,
                                language="zh",
                                response_format="text"
                            )

                        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                        Path(temp_file.name).unlink(missing_ok=True)

                        if not transcript or not transcript.strip():
                            logger.debug(f"Empty transcript for chunk {chunk_sequence}")
                            return None

                        return {
                            'text': transcript.strip(),
                            'chunk_sequence': chunk_sequence,
                            'session_id': str(session_id),
                            'timestamp': datetime.utcnow().isoformat(),
                            'language': 'zh-TW',
                            'duration': CHUNK_DURATION
                        }

                    finally:
                        # ç¢ºä¿æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                        Path(temp_file.name).unlink(missing_ok=True)

        except Exception as e:
            logger.error(f"Whisper transcription failed for chunk {chunk_sequence}: {e}")
            # å»£æ’­ Whisper API éŒ¯èª¤åˆ°å‰ç«¯
            await self._broadcast_transcription_error(session_id, chunk_sequence, "whisper_api_error", f"Azure OpenAI Whisper è½‰éŒ„å¤±æ•—: {str(e)}")
            return None

    async def _save_and_push_result(self, session_id: UUID, chunk_sequence: int, transcript_result: Dict[str, Any]):
        """å„²å­˜è½‰éŒ„çµæœä¸¦æ¨é€åˆ°å‰ç«¯"""
        try:
            # å„²å­˜åˆ°è³‡æ–™åº«
            supabase = get_supabase_client()

            segment_data = {
                "session_id": str(session_id),
                "chunk_sequence": chunk_sequence,
                "text": transcript_result['text'],
                "start_time": chunk_sequence * CHUNK_DURATION,
                "end_time": (chunk_sequence + 1) * CHUNK_DURATION,
                "confidence": 1.0,
                "language": transcript_result.get('language', 'zh-TW'),
                "created_at": transcript_result['timestamp']
            }

            response = supabase.table("transcript_segments").insert(segment_data).execute()

            if response.data:
                segment_id = response.data[0]['id']
                logger.debug(f"Saved transcript segment {segment_id} for chunk {chunk_sequence}")

                # é€é WebSocket å»£æ’­è½‰éŒ„çµæœ
                # è‹¥å°šæœªå»£æ’­ active ç›¸ä½ï¼Œå…ˆé€å‡º
                if str(session_id) not in _active_phase_sent:
                    logger.info(f"ğŸš€ [è½‰éŒ„æ¨é€] é¦–æ¬¡å»£æ’­ active ç›¸ä½åˆ° session {session_id}")
                    await transcript_manager.broadcast(
                        json.dumps({"phase": "active"}),
                        str(session_id)
                    )
                    _active_phase_sent.add(str(session_id))
                    logger.info(f"âœ… [è½‰éŒ„æ¨é€] Active ç›¸ä½å»£æ’­å®Œæˆ for session {session_id}")

                # æ§‹å»ºé€å­—ç¨¿ç‰‡æ®µè¨Šæ¯
                transcript_message = {
                    "type": "transcript_segment",
                    "session_id": str(session_id),
                    "segment_id": segment_id,
                    "text": transcript_result['text'],
                    "chunk_sequence": chunk_sequence,
                    "start_sequence": chunk_sequence,  # æ·»åŠ  start_sequence æ¬„ä½
                    "start_time": segment_data['start_time'],
                    "end_time": segment_data['end_time'],
                    "confidence": segment_data['confidence'],
                    "timestamp": segment_data['created_at']
                }

                logger.info(f"ğŸ“¡ [è½‰éŒ„æ¨é€] å»£æ’­é€å­—ç¨¿ç‰‡æ®µåˆ° session {session_id}:")
                logger.info(f"   - æ–‡å­—: '{transcript_result['text'][:50]}{'...' if len(transcript_result['text']) > 50 else ''}'")
                logger.info(f"   - åºè™Ÿ: {chunk_sequence}")
                logger.info(f"   - æ™‚é–“: {segment_data['start_time']}s - {segment_data['end_time']}s")

                await transcript_manager.broadcast(
                    json.dumps(transcript_message),
                    str(session_id)
                )

                logger.info(f"âœ… [è½‰éŒ„æ¨é€] é€å­—ç¨¿ç‰‡æ®µå»£æ’­å®Œæˆ for session {session_id}")

                # å»£æ’­è½‰éŒ„å®Œæˆæ¶ˆæ¯
                logger.info(f"å»£æ’­è½‰éŒ„å®Œæˆè¨Šæ¯åˆ° session {session_id}")
                await transcript_manager.broadcast(
                    json.dumps({
                        "type": "transcript_complete",
                        "session_id": str(session_id),
                        "message": "Transcription completed for the batch."
                    }),
                    str(session_id)
                )
                logger.info(f"è½‰éŒ„ä»»å‹™å®Œæˆ for session: {session_id}, chunk: {chunk_sequence}")

        except Exception as e:
            logger.error(f"Failed to save/push transcript for chunk {chunk_sequence}: {e}")
            # å»£æ’­è½‰éŒ„å¤±æ•—éŒ¯èª¤åˆ°å‰ç«¯
            await self._broadcast_transcription_error(session_id, chunk_sequence, "database_error", f"è³‡æ–™åº«æ“ä½œå¤±æ•—: {str(e)}")

    async def _broadcast_transcription_error(self, session_id: UUID, chunk_sequence: int, error_type: str, error_message: str):
        """å»£æ’­è½‰éŒ„éŒ¯èª¤åˆ°å‰ç«¯"""
        try:
            from app.ws.transcript_feed import manager as transcript_manager
            error_data = {
                "type": "transcription_error",
                "error_type": error_type,
                "message": error_message,
                "session_id": str(session_id),
                "chunk_sequence": chunk_sequence,
                "timestamp": datetime.utcnow().isoformat()
            }
            await transcript_manager.broadcast(
                json.dumps(error_data),
                str(session_id)
            )
            logger.info(f"ğŸš¨ [è½‰éŒ„éŒ¯èª¤å»£æ’­] å·²é€šçŸ¥å‰ç«¯è½‰éŒ„éŒ¯èª¤: {error_type}")
        except Exception as e:
            logger.error(f"Failed to broadcast transcription error: {e}")

    # TODO: åœ¨æ­¤è™•å¯¦ç¾æ›´å„ªé›…çš„é—œé–‰é‚è¼¯
    logger.info("Transcription service is shutting down...")

# ----------------------
# å…¼å®¹èˆŠæ¸¬è©¦çš„å·¥å» å‡½å¼èˆ‡å…¨åŸŸè®Šæ•¸
# ----------------------

_transcription_service_v2: Optional[SimpleAudioTranscriptionService] = None


def get_azure_openai_client() -> Optional[AzureOpenAI]:
    """æ ¹æ“šç’°å¢ƒè®Šæ•¸å»ºç«‹ AzureOpenAI ç”¨æˆ¶ç«¯ï¼Œç¼ºå€¼æ™‚å›å‚³ Noneã€‚"""
    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    if not api_key or not endpoint:
        return None
    # ä½¿ç”¨é è¨­ API ç‰ˆæœ¬å³å¯
    return AzureOpenAI(api_key=api_key, api_version="2024-06-01", azure_endpoint=endpoint)


def get_whisper_deployment_name() -> Optional[str]:
    """å–å¾— Whisper éƒ¨ç½²åç¨±ï¼Œç’°å¢ƒè®Šæ•¸ç¼ºå€¼æ™‚å›å‚³ Noneã€‚"""
    return os.getenv("WHISPER_DEPLOYMENT_NAME")


async def initialize_transcription_service_v2() -> Optional[SimpleAudioTranscriptionService]:
    """åˆå§‹åŒ–ä¸¦å¿«å– SimpleAudioTranscriptionService å¯¦ä¾‹ã€‚è‹¥è¨­å®šä¸è¶³å‰‡å›å‚³ Noneã€‚"""
    global _transcription_service_v2
    if _transcription_service_v2 is not None:
        return _transcription_service_v2

    client = get_azure_openai_client()
    deployment = get_whisper_deployment_name()
    if not client or not deployment:
        logger.warning("Azure OpenAI è¨­å®šä¸è¶³ï¼Œç„¡æ³•åˆå§‹åŒ–è½‰éŒ„æœå‹™ v2")
        return None

    _transcription_service_v2 = SimpleAudioTranscriptionService(client, deployment)
    logger.info("âœ… Transcription service v2 initialized")
    return _transcription_service_v2


def cleanup_transcription_service_v2():
    """æ¸…ç†å…¨åŸŸè½‰éŒ„æœå‹™å¯¦ä¾‹ã€‚"""
    global _transcription_service_v2
    _transcription_service_v2 = None
