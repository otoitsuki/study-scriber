#!/usr/bin/env python3
"""
éŸ³è¨Šè½‰éŒ„æœå‹™ v2
ä½¿ç”¨å¤§åˆ‡ç‰‡ï¼ˆ10-15ç§’ï¼‰+ ç›´æ¥è½‰æ›çš„æ¶æ§‹ï¼Œé¿å…è¤‡é›œçš„ WebM åˆä½µ
"""

import asyncio
import logging
import subprocess
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, Any
from uuid import UUID
import json

from openai import AzureOpenAI

from .azure_openai import PerformanceTimer
from ..db.database import get_supabase_client
from app.db.database import get_async_session
from app.db import models
from app.core.config import settings
from app.ws.transcript_feed import manager as transcript_manager
from app.services.r2_client import R2Client

logger = logging.getLogger(__name__)

# é…ç½®å¸¸æ•¸
CHUNK_DURATION = 12  # 12 ç§’åˆ‡ç‰‡
PROCESSING_TIMEOUT = 30  # è™•ç†è¶…æ™‚ï¼ˆç§’ï¼‰
MAX_RETRIES = 3  # æœ€å¤§é‡è©¦æ¬¡æ•¸


class SimpleAudioTranscriptionService:
    """ç°¡åŒ–çš„éŸ³è¨Šè½‰éŒ„æœå‹™"""

    def __init__(self, azure_client: AzureOpenAI, deployment_name: str):
        self.client = azure_client
        self.deployment_name = deployment_name
        self.processing_tasks: Dict[str, asyncio.Task] = {}

    async def process_audio_chunk(self, session_id: UUID, chunk_sequence: int, webm_data: bytes) -> bool:
        """
        è™•ç†å–®ä¸€éŸ³è¨Šåˆ‡ç‰‡

        Args:
            session_id: æœƒè©± ID
            chunk_sequence: åˆ‡ç‰‡åºè™Ÿ
            webm_data: WebM éŸ³è¨Šæ•¸æ“š

        Returns:
            bool: è™•ç†æ˜¯å¦æˆåŠŸ
        """
        task_key = f"{session_id}_{chunk_sequence}"

        # é¿å…é‡è¤‡è™•ç†
        if task_key in self.processing_tasks:
            logger.debug(f"Chunk {chunk_sequence} already being processed for session {session_id}")
            return False

        # å»ºç«‹è™•ç†ä»»å‹™
        task = asyncio.create_task(
            self._process_chunk_async(session_id, chunk_sequence, webm_data)
        )
        self.processing_tasks[task_key] = task

        # æ¸…ç†å®Œæˆçš„ä»»å‹™
        task.add_done_callback(lambda t: self.processing_tasks.pop(task_key, None))

        return True

    async def _process_chunk_async(self, session_id: UUID, chunk_sequence: int, webm_data: bytes):
        """éåŒæ­¥è™•ç†éŸ³è¨Šåˆ‡ç‰‡"""
        try:
            with PerformanceTimer(f"Process chunk {chunk_sequence} for session {session_id}"):
                logger.info(f"ğŸµ é–‹å§‹è™•ç†éŸ³è¨Šåˆ‡ç‰‡ {chunk_sequence} (session: {session_id}, size: {len(webm_data)} bytes)")

                # æ­¥é©Ÿ 1: é©—è­‰ WebM æ•¸æ“š
                if not self._validate_webm_data(webm_data, chunk_sequence):
                    return

                # æ­¥é©Ÿ 2: WebM â†’ WAV è½‰æ›
                wav_data = await self._convert_webm_to_wav(webm_data, chunk_sequence)
                if not wav_data:
                    logger.error(f"Failed to convert WebM to WAV for chunk {chunk_sequence}")
                    return

                # æ­¥é©Ÿ 3: Whisper è½‰éŒ„
                transcript_result = await self._transcribe_audio(wav_data, session_id, chunk_sequence)
                if not transcript_result:
                    logger.error(f"Failed to transcribe chunk {chunk_sequence}")
                    return

                # æ­¥é©Ÿ 4: å„²å­˜ä¸¦æ¨é€çµæœ
                await self._save_and_push_result(session_id, chunk_sequence, transcript_result)

                logger.info(f"âœ… æˆåŠŸè™•ç†éŸ³è¨Šåˆ‡ç‰‡ {chunk_sequence}: '{transcript_result.get('text', '')[:50]}...'")

        except Exception as e:
            logger.error(f"Error processing chunk {chunk_sequence} for session {session_id}: {e}", exc_info=True)

    def _validate_webm_data(self, webm_data: bytes, chunk_sequence: int) -> bool:
        """é©—è­‰ WebM æ•¸æ“š - ç°¡åŒ–ç‰ˆæœ¬ï¼Œä¿¡ä»»ç€è¦½å™¨ç”¢ç”Ÿçš„è³‡æ–™"""
        if not webm_data or len(webm_data) < 50:
            logger.warning(f"WebM chunk {chunk_sequence} too small: {len(webm_data) if webm_data else 0} bytes")
            return False

        # ç§»é™¤ EBML æ¨™é ­æª¢æŸ¥ï¼Œä¿¡ä»» MediaRecorder ç”¢ç”Ÿçš„è³‡æ–™
        # FFmpeg æœƒç”¨ -fflags +genpts è™•ç†ä¸å®Œæ•´çš„æµå¼è³‡æ–™
        return True

    async def _convert_webm_to_wav(self, webm_data: bytes, chunk_sequence: int) -> Optional[bytes]:
        """å°‡ WebM / fMP4 è½‰æ›ç‚º WAVï¼Œè‡ªå‹•è¾¨è­˜ä¾†æºæ ¼å¼"""

        def _detect_format(data: bytes) -> str:
            """ç°¡æ˜“æª¢æ¸¬éŸ³è¨Šå°è£æ ¼å¼ (webm / mp4)"""
            if len(data) < 12:
                return 'unknown'
            # WebM (Matroska) ä»¥ EBML header é–‹é ­ 0x1A45DFA3
            if data[0:4] == b'\x1A\x45\xDF\xA3':
                return 'webm'
            # MP4/ISOBMFF å¸¸åœ¨ 4â€“8 byte çœ‹åˆ° 'ftyp'
            if b'ftyp' in data[4:12]:
                return 'mp4'
            return 'unknown'

        try:
            audio_format = _detect_format(webm_data)
            with PerformanceTimer(f"{audio_format.upper()} to WAV conversion for chunk {chunk_sequence}"):

                # åŸºæœ¬ FFmpeg åƒæ•¸
                cmd = ['ffmpeg']

                # ä¾ä¾†æºæ ¼å¼æ±ºå®šè¼¸å…¥åƒæ•¸
                if audio_format == 'mp4':
                    # Safari ç”¢å‡ºçš„ fragmented MP4
                    cmd += ['-f', 'mp4']
                # é€šç”¨æ——æ¨™ï¼šç”Ÿæˆæ™‚é–“æˆ³è™•ç†ä¸å®Œæ•´æµ
                cmd += ['-fflags', '+genpts', '-i', 'pipe:0', '-ac', '1', '-ar', '16000', '-f', 'wav', '-y', 'pipe:1']

                process = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdin=asyncio.subprocess.PIPE,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )

                stdout, stderr = await asyncio.wait_for(
                    process.communicate(input=webm_data),
                    timeout=PROCESSING_TIMEOUT
                )

                if process.returncode != 0:
                    error_msg = stderr.decode('utf-8', errors='ignore') if stderr else "Unknown error"
                    logger.error(f"FFmpeg conversion failed for chunk {chunk_sequence}: {error_msg}")
                    return None

                if not stdout or len(stdout) < 100:
                    logger.error(
                        f"FFmpeg produced insufficient WAV data for chunk {chunk_sequence}: {len(stdout) if stdout else 0} bytes")
                    return None

                logger.debug(
                    f"Successfully converted {audio_format.upper()} ({len(webm_data)} bytes) to WAV ({len(stdout)} bytes)")
                return stdout

        except asyncio.TimeoutError:
            logger.error(f"FFmpeg conversion timeout for chunk {chunk_sequence}")
            return None
        except Exception as e:
            logger.error(f"FFmpeg conversion error for chunk {chunk_sequence}: {e}")
            return None

    async def _transcribe_audio(self, wav_data: bytes, session_id: UUID, chunk_sequence: int) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨ Azure OpenAI Whisper è½‰éŒ„éŸ³è¨Š"""
        try:
            with PerformanceTimer(f"Whisper transcription for chunk {chunk_sequence}"):
                # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                    temp_file.write(wav_data)
                    temp_file.flush()

                    try:
                        # Whisper API å‘¼å«
                        with open(temp_file.name, 'rb') as audio_file:
                            transcript = self.client.audio.transcriptions.create(
                                model=self.deployment_name,
                                file=audio_file,
                                language="zh",
                                response_format="text"
                            )

                        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                        Path(temp_file.name).unlink(missing_ok=True)

                        if not transcript or not transcript.strip():
                            logger.debug(f"Empty transcript for chunk {chunk_sequence}")
                            return None

                        return {
                            'text': transcript.strip(),
                            'chunk_sequence': chunk_sequence,
                            'session_id': str(session_id),
                            'timestamp': datetime.utcnow().isoformat(),
                            'language': 'zh-TW',
                            'duration': CHUNK_DURATION
                        }

                    finally:
                        # ç¢ºä¿æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                        Path(temp_file.name).unlink(missing_ok=True)

        except Exception as e:
            logger.error(f"Whisper transcription failed for chunk {chunk_sequence}: {e}")
            return None

    async def _save_and_push_result(self, session_id: UUID, chunk_sequence: int, transcript_result: Dict[str, Any]):
        """å„²å­˜è½‰éŒ„çµæœä¸¦æ¨é€åˆ°å‰ç«¯"""
        try:
            # å„²å­˜åˆ°è³‡æ–™åº«
            supabase = get_supabase_client()

            segment_data = {
                "session_id": str(session_id),
                "chunk_sequence": chunk_sequence,
                "text": transcript_result['text'],
                "start_time": chunk_sequence * CHUNK_DURATION,
                "end_time": (chunk_sequence + 1) * CHUNK_DURATION,
                "confidence": 1.0,
                "language": transcript_result.get('language', 'zh-TW'),
                "created_at": transcript_result['timestamp']
            }

            response = supabase.table("transcript_segments").insert(segment_data).execute()

            if response.data:
                segment_id = response.data[0]['id']
                logger.debug(f"Saved transcript segment {segment_id} for chunk {chunk_sequence}")

                # é€é WebSocket å»£æ’­è½‰éŒ„çµæœ
                logger.info(f"å»£æ’­é€å­—ç¨¿ç‰‡æ®µåˆ° session {session_id}")
                await transcript_manager.broadcast(
                    json.dumps({
                        "type": "transcript_segment",
                        "session_id": str(session_id),
                        "segment_id": segment_id,
                        "text": transcript_result['text'],
                        "chunk_sequence": chunk_sequence,
                        "start_time": segment_data['start_time'],
                        "end_time": segment_data['end_time'],
                        "timestamp": segment_data['created_at']
                    }),
                    str(session_id)
                )

                # å»£æ’­è½‰éŒ„å®Œæˆæ¶ˆæ¯
                logger.info(f"å»£æ’­è½‰éŒ„å®Œæˆè¨Šæ¯åˆ° session {session_id}")
                await transcript_manager.broadcast(
                    json.dumps({
                        "type": "transcript_complete",
                        "session_id": str(session_id),
                        "message": "Transcription completed for the batch."
                    }),
                    str(session_id)
                )
                logger.info(f"è½‰éŒ„ä»»å‹™å®Œæˆ for session: {session_id}, task_key: {task_key}")

        except Exception as e:
            logger.error(f"Failed to save/push transcript for chunk {chunk_sequence}: {e}")


# å…¨åŸŸæœå‹™å¯¦ä¾‹
_transcription_service_v2: Optional[SimpleAudioTranscriptionService] = None


def get_azure_openai_client() -> Optional[AzureOpenAI]:
    """å–å¾— Azure OpenAI å®¢æˆ¶ç«¯"""
    import os

    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-06-01")

    if not api_key or not endpoint:
        logger.warning("Azure OpenAI credentials not configured")
        return None

    return AzureOpenAI(
        api_key=api_key,
        api_version=api_version,
        azure_endpoint=endpoint
    )


def get_whisper_deployment_name() -> Optional[str]:
    """å–å¾— Whisper éƒ¨ç½²åç¨±"""
    import os
    return os.getenv("WHISPER_DEPLOYMENT_NAME")


async def initialize_transcription_service_v2():
    global _transcription_service_v2
    if _transcription_service_v2 is None:
        client = get_azure_openai_client()
        deployment = get_whisper_deployment_name()
        if client and deployment:
            _transcription_service_v2 = SimpleAudioTranscriptionService(client, deployment)
    return _transcription_service_v2


def cleanup_transcription_service_v2():
    """æ¸…ç†è½‰éŒ„æœå‹™"""
    global _transcription_service_v2

    if _transcription_service_v2:
        # å–æ¶ˆæ‰€æœ‰é€²è¡Œä¸­çš„ä»»å‹™
        for task in _transcription_service_v2.processing_tasks.values():
            if not task.done():
                task.cancel()

        _transcription_service_v2 = None
        logger.info("âœ… è½‰éŒ„æœå‹™ v2 æ¸…ç†å®Œæˆ")

# å–å¾—å–®ä¾‹
get_transcription_service_v2 = lambda: _transcription_service_v2

# å…¬é–‹å–®ä¾‹ä»‹é¢ï¼Œä¾› main.py ç­‰å¤–éƒ¨æ¨¡çµ„ç›´æ¥ import
transcription_service = _transcription_service_v2
