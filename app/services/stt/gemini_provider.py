from __future__ import annotations

import base64
import logging
from datetime import datetime
from typing import Dict, Any
from uuid import UUID

import google.generativeai as genai

from app.core.config import get_settings
from app.core.ffmpeg import webm_to_pcm
from .base import ISTTProvider

logger = logging.getLogger(__name__)
settings = get_settings()


class GeminiProvider(ISTTProvider):
    """ä½¿ç”¨ Vertex AI Gemini 2.5 Pro çš„èªéŸ³è½‰æ–‡å­— Providerã€‚"""

    def __init__(self) -> None:
        # å»¶é²è¼‰å…¥ï¼Œé¿å…æœªè¨­å®š API Key ä»å»ºç«‹ç‰©ä»¶
        self._model: genai.GenerativeModel | None = None

    # ------------- ä»‹é¢å¯¦ä½œ -------------
    def name(self) -> str:  # type: ignore[override]
        return "gemini"

    def max_rpm(self) -> int:  # type: ignore[override]
        return settings.GEMINI_MAX_REQUESTS if hasattr(settings, "GEMINI_MAX_REQUESTS") else 60

    async def transcribe(self, webm: bytes, session_id: UUID, chunk_seq: int) -> Dict[str, Any]:  # type: ignore[override]
        """å°‡ WebM è½‰ç‚º PCMï¼Œé€è‡³ Gemini å–å¾—çµæœã€‚"""
        logger.info(f"ğŸ™ï¸ [Gemini] é–‹å§‹è½‰éŒ„ chunk {chunk_seq} (session {session_id})")

        # åˆå§‹åŒ–æ¨¡å‹
        if self._model is None:
            try:
                # ä½¿ç”¨æ–°ç‰ˆ google-generativeai éœ€è¦å…ˆå…¨åŸŸè¨­å®š API Key
                genai.configure(api_key=settings.GEMINI_API_KEY)
                # å»ºç«‹æ¨¡å‹ï¼Œä¸å†æ¥å— api_key/base_url åƒæ•¸
                self._model = genai.GenerativeModel("gemini-2.5-pro-preview")
            except Exception as e:
                logger.error(f"[Gemini] åˆå§‹åŒ–æ¨¡å‹å¤±æ•—: {e}")
                raise

        # 1. è½‰æª”
        pcm_bytes = await webm_to_pcm(webm)

        # 2. çµ„ prompt
        prompt = getattr(settings, "GEMINI_PROMPT", "è«‹è¼¸å‡ºé€å­—ç¨¿ï¼š")

        # 3. å‘¼å« API - ä½¿ç”¨ inline_data æ–¹å¼å‚³ééŸ³è¨Š (ç¬¦åˆæ–°ç‰ˆ google-generativeai SDK)
        try:
            from google.generativeai import types as genai_types  # type: ignore

            parts = [
                {"text": prompt},
                genai_types.Part.from_bytes(data=pcm_bytes, mime_type="audio/wav"),
            ]

            res = await self._model.generate_content_async(contents=parts)

            text = res.text.strip() if hasattr(res, "text") else ""
        except Exception as e:
            logger.error(f"[Gemini] è½‰éŒ„å¤±æ•—: {e}")
            raise

        logger.info(f"âœ… [Gemini] chunk {chunk_seq} è½‰éŒ„å®Œæˆï¼Œé•·åº¦ {len(text)} å­—")
        return {
            "text": text,
            "chunk_sequence": chunk_seq,
            "session_id": str(session_id),
            "timestamp": datetime.utcnow().isoformat(),
            "start_time": chunk_seq * settings.AUDIO_CHUNK_DURATION_SEC,
            "end_time": (chunk_seq + 1) * settings.AUDIO_CHUNK_DURATION_SEC,
            "provider": self.name(),
        }
