"""
æ–‡æœ¬å“è³ªæª¢æŸ¥å·¥å…·
ç”¨æ–¼æª¢æ¸¬å’Œéæ¿¾ Whisper å¹»è¦ºè¼¸å‡º
"""

import re
import logging
from typing import List, Pattern

logger = logging.getLogger(__name__)


def is_low_quality_text(
    text: str,
    max_repetition_ratio: float = 0.7,  # æ”¾å¯¬é–€æª»ï¼Œé¿å…èª¤åˆ¤æ­£å¸¸ä¸­æ–‡
    min_char_threshold: int = 2,
    check_patterns: bool = True,
    check_diversity: bool = True,
    check_sentence_repetition: bool = True,
    check_phrase_repetition: bool = True
) -> bool:
    """
    æª¢æ¸¬æ–‡æœ¬æ˜¯å¦ç‚ºä½å“è³ªï¼ˆå¹»è¦ºè¼¸å‡ºï¼‰

    Args:
        text: è¦æª¢æ¸¬çš„æ–‡æœ¬
        max_repetition_ratio: æœ€å¤§é‡è¤‡æ¯”ä¾‹é–€æª»
        min_char_threshold: æœ€å°å­—ç¬¦æ•¸é–€æª»
        check_patterns: æ˜¯å¦æª¢æŸ¥å¹»è¦ºæ¨¡å¼
        check_diversity: æ˜¯å¦æª¢æŸ¥å­—ç¬¦å¤šæ¨£æ€§
        check_sentence_repetition: æ˜¯å¦æª¢æŸ¥å¥å­é‡è¤‡
        check_phrase_repetition: æ˜¯å¦æª¢æŸ¥è©çµ„é‡è¤‡

    Returns:
        bool: æ˜¯å¦ç‚ºä½å“è³ªæ–‡æœ¬
    """
    if not text or len(text.strip()) < min_char_threshold:
        return True

    text = text.strip()

    # 1. æª¢æ¸¬å¥å­é‡è¤‡æ¨¡å¼
    if check_sentence_repetition and is_sentence_repetitive(text):
        logger.debug(f"ğŸ”„ [å“è³ªæª¢æŸ¥] æª¢æ¸¬åˆ°å¥å­é‡è¤‡: '{text[:30]}...'")
        return True

    # 2. æª¢æ¸¬è©çµ„é‡è¤‡æ¨¡å¼
    if check_phrase_repetition and is_phrase_repetitive(text):
        logger.debug(f"ğŸ”„ [å“è³ªæª¢æŸ¥] æª¢æ¸¬åˆ°è©çµ„é‡è¤‡: '{text[:30]}...'")
        return True

    # 3. æª¢æ¸¬é‡è¤‡å­—ç¬¦æ¨¡å¼
    char_counts = {}
    for char in text:
        if char.strip():  # å¿½ç•¥ç©ºç™½å­—ç¬¦
            char_counts[char] = char_counts.get(char, 0) + 1

    if char_counts:
        # è¨ˆç®—æœ€é«˜é »å­—ç¬¦çš„æ¯”ä¾‹
        max_char_count = max(char_counts.values())
        repetition_ratio = max_char_count / len(text.replace(' ', ''))

        if repetition_ratio > max_repetition_ratio:
            logger.debug(
                f"ğŸ”„ [å“è³ªæª¢æŸ¥] é«˜é‡è¤‡æ¯”ä¾‹: {repetition_ratio:.2f} > {max_repetition_ratio}, "
                f"æ–‡æœ¬: '{text[:20]}...'"
            )
            return True

    # æª¢æ¸¬å¸¸è¦‹çš„ Whisper å¹»è¦ºæ¨¡å¼
    if check_patterns:
        hallucination_patterns = get_hallucination_patterns()

        for pattern_obj in hallucination_patterns:
            if pattern_obj.search(text):
                logger.debug(f"ğŸ”„ [å“è³ªæª¢æŸ¥] æª¢æ¸¬åˆ°å¹»è¦ºæ¨¡å¼: '{text[:20]}...'")
                return True

    # æª¢æŸ¥å­—ç¬¦å¤šæ¨£æ€§ (å°ä¸­æ–‡æ›´å¯¬é¬†)
    if check_diversity:
        unique_chars = set(text.replace(' ', ''))
        # ä¸­æ–‡å­—ç¬¦éœ€è¦æ›´å¯¬é¬†çš„æª¢æŸ¥ï¼Œå› ç‚ºå¸¸ç”¨å­—æœƒé‡è¤‡å‡ºç¾
        diversity_threshold = 1 if len(text) <= 5 else 2
        if len(unique_chars) <= diversity_threshold and len(text) > 15:  # æé«˜é•·åº¦é–€æª»
            logger.debug(f"ğŸ”„ [å“è³ªæª¢æŸ¥] å­—ç¬¦å¤šæ¨£æ€§éä½: '{text[:20]}...'")
            return True

    return False


def get_hallucination_patterns() -> List[Pattern]:
    """
    ç²å–å¸¸è¦‹çš„å¹»è¦ºæ¨¡å¼æ­£è¦è¡¨é”å¼åˆ—è¡¨

    Returns:
        List[Pattern]: ç·¨è­¯å¾Œçš„æ­£è¦è¡¨é”å¼æ¨¡å¼åˆ—è¡¨
    """
    patterns = [
        r'^([ä¹–å—¯å‘ƒå•Šå“¦å™¢å”‰]{3,})+$',  # ç´”é‡è¤‡ä¸­æ–‡å­—ç¬¦ (è‡³å°‘3å€‹)
        r'^([a-zA-Z])\1{4,}',          # é‡è¤‡è‹±æ–‡å­—ç¬¦ (è‡³å°‘5å€‹)
        r'^(.{1,2})\1{4,}$',          # çŸ­æ¨¡å¼é‡è¤‡ (æ›´åš´æ ¼çš„æª¢æŸ¥)
        r'^(è¬è¬è§€çœ‹|è¬è¬æ”¶è½|è«‹è¨‚é–±|Subscribe|Thanks for watching)$',  # åªåŒ¹é…ç´”å¹»è¦ºçŸ­èª
        r'^[.,!?;:\s]*$',             # åªæœ‰æ¨™é»ç¬¦è™Ÿ
        r'^(å“ˆ){4,}$',                # é‡è¤‡ç¬‘è² (æ›´åš´æ ¼)
        r'^(å˜¿){4,}$',                # é‡è¤‡æ„Ÿå˜†è© (æ›´åš´æ ¼)
        r'^([æ¬¸èª’å‘€å–”]{3,})+$',       # å…¶ä»–é‡è¤‡èªæ°£è©
    ]

    return [re.compile(pattern, re.IGNORECASE) for pattern in patterns]


def is_repetitive_text(
    text: str,
    max_repetition_ratio: float = 0.6,
    min_char_threshold: int = 3
) -> bool:
    """
    å°ˆé–€æª¢æ¸¬é‡è¤‡æ–‡æœ¬æ¨¡å¼ï¼ˆèˆ‡ localhost-whisper æœå‹™ä¿æŒä¸€è‡´ï¼‰

    Args:
        text: è¦æª¢æ¸¬çš„æ–‡æœ¬
        max_repetition_ratio: æœ€å¤§é‡è¤‡æ¯”ä¾‹
        min_char_threshold: æœ€å°‘å­—ç¬¦æ•¸é–€æª»

    Returns:
        bool: æ˜¯å¦ç‚ºé‡è¤‡æ–‡æœ¬
    """
    if not text or len(text.strip()) < min_char_threshold:
        return True  # ç©ºæ–‡æœ¬æˆ–éçŸ­æ–‡æœ¬è¦–ç‚ºä½å“è³ª

    text = text.strip()

    # æª¢æ¸¬å–®å­—ç¬¦é‡è¤‡æ¨¡å¼
    char_counts = {}
    for char in text:
        if char.strip():  # å¿½ç•¥ç©ºç™½å­—ç¬¦
            char_counts[char] = char_counts.get(char, 0) + 1

    if char_counts:
        # è¨ˆç®—æœ€é«˜é »å­—ç¬¦çš„æ¯”ä¾‹
        max_char_count = max(char_counts.values())
        repetition_ratio = max_char_count / len(text.replace(' ', ''))

        if repetition_ratio > max_repetition_ratio:
            logger.debug(
                f"ğŸ”„ [é‡è¤‡æª¢æ¸¬] é«˜é‡è¤‡æ¯”ä¾‹: {repetition_ratio:.2f} > {max_repetition_ratio}, "
                f"æ–‡æœ¬: '{text[:20]}...'"
            )
            return True

    # æª¢æ¸¬å¸¸è¦‹çš„ Whisper å¹»è¦ºæ¨¡å¼
    hallucination_patterns = [
        r'^([ä¹–å—¯å‘ƒå•Šå“¦]{3,})',  # é‡è¤‡çš„ä¸­æ–‡å­—ç¬¦
        r'^([a-zA-Z])\1{4,}',      # é‡è¤‡çš„è‹±æ–‡å­—ç¬¦
        r'^(.{1,2})\1{3,}',       # çŸ­æ¨¡å¼é‡è¤‡
        r'(è¬è¬è§€çœ‹|è¬è¬æ”¶è½|è¬è¬|æ„Ÿè¬|Subscribe)',  # å¸¸è¦‹çš„å¹»è¦ºçŸ­èª
    ]

    for pattern in hallucination_patterns:
        if re.search(pattern, text):
            logger.debug(f"ğŸ”„ [æ¨¡å¼æª¢æ¸¬] æª¢æ¸¬åˆ°å¹»è¦ºæ¨¡å¼: '{text[:20]}...'")
            return True

    return False


def is_sentence_repetitive(text: str, max_repetition_ratio: float = 0.8) -> bool:
    """
    æª¢æ¸¬å¥å­é‡è¤‡æ¨¡å¼

    Args:
        text: è¦æª¢æ¸¬çš„æ–‡æœ¬
        max_repetition_ratio: æœ€å¤§é‡è¤‡å¥å­æ¯”ä¾‹

    Returns:
        bool: æ˜¯å¦åŒ…å«é‡è¤‡å¥å­
    """
    # æŒ‰ä¸­æ–‡å¥è™Ÿã€è‹±æ–‡å¥è™Ÿã€å•è™Ÿã€æ„Ÿå˜†è™Ÿåˆ†å‰²å¥å­
    sentences = re.split(r'[ã€‚.!?ï¼ï¼Ÿ]', text)
    sentences = [s.strip() for s in sentences if s.strip()]

    if len(sentences) <= 1:
        return False

    # è¨ˆç®—æ¯å€‹å¥å­çš„å‡ºç¾æ¬¡æ•¸
    sentence_counts = {}
    for sentence in sentences:
        if len(sentence) > 2:  # å¿½ç•¥éçŸ­çš„å¥å­ç‰‡æ®µ
            sentence_counts[sentence] = sentence_counts.get(sentence, 0) + 1

    if not sentence_counts:
        return False

    # æª¢æŸ¥æ˜¯å¦æœ‰å¥å­é‡è¤‡æ¬¡æ•¸éé«˜
    max_count = max(sentence_counts.values())
    total_sentences = len(sentences)
    repetition_ratio = max_count / total_sentences

    return repetition_ratio > max_repetition_ratio


def is_phrase_repetitive(text: str, max_repetition_ratio: float = 0.9) -> bool:
    """
    æª¢æ¸¬è©çµ„/å–®è©é‡è¤‡æ¨¡å¼

    Args:
        text: è¦æª¢æ¸¬çš„æ–‡æœ¬
        max_repetition_ratio: æœ€å¤§é‡è¤‡è©çµ„æ¯”ä¾‹

    Returns:
        bool: æ˜¯å¦åŒ…å«é‡è¤‡è©çµ„
    """
    # æŒ‰ç©ºæ ¼åˆ†å‰²è©çµ„ï¼ŒåŒæ™‚è™•ç†ä¸­è‹±æ–‡æ··åˆ
    words = text.split()
    if len(words) <= 2:
        return False

    # è¨ˆç®—æ¯å€‹è©çš„å‡ºç¾æ¬¡æ•¸
    word_counts = {}
    for word in words:
        word = word.strip('~,.!?;:')  # å»é™¤æ¨™é»ç¬¦è™Ÿ
        if len(word) > 1:  # å¿½ç•¥å–®å­—ç¬¦è©
            word_counts[word] = word_counts.get(word, 0) + 1

    if not word_counts:
        return False

    # æª¢æŸ¥æ˜¯å¦æœ‰è©é‡è¤‡æ¬¡æ•¸éé«˜
    max_count = max(word_counts.values())
    total_words = len(words)
    repetition_ratio = max_count / total_words

    # ç‰¹åˆ¥æª¢æŸ¥é€£çºŒé‡è¤‡è©çµ„æ¨¡å¼ (å¦‚ "yeah~yeah yeah")
    text_lower = text.lower()
    if re.search(r'(\b\w+[~]*\w*\b)\s*\1\s*\1', text_lower):  # é€£çºŒ3æ¬¡ç›¸åŒè©çµ„
        return True

    return repetition_ratio > max_repetition_ratio


def remove_text_repetitions(text: str, max_ngram_size: int = 6) -> str:
    """
    ç§»é™¤æ–‡æœ¬ä¸­çš„é‡è¤‡ n-gram æ¨¡å¼

    Args:
        text: åŸå§‹æ–‡æœ¬
        max_ngram_size: æœ€å¤§ n-gram é•·åº¦

    Returns:
        str: å»é‡å¾Œçš„æ–‡æœ¬
    """
    if not text or not text.strip():
        return text

    result = text
    original_length = len(text)

    # å¾å¤§åˆ°å°çš„ n-gram é€²è¡Œå»é‡ï¼Œé¿å…ç ´å£è¼ƒé•·çš„æ­£å¸¸é‡è¤‡
    for n in range(max_ngram_size, 1, -1):
        result = _remove_ngram_repetitions(result, n)

    # ç‰¹åˆ¥è™•ç†ä¸­æ–‡å¸¸è¦‹çš„ç–Šå­—å•é¡Œ
    result = _remove_chinese_repetitions(result)

    if len(result) != original_length:
        logger.debug(f"ğŸ”§ [å»é‡] æ–‡æœ¬é•·åº¦å¾ {original_length} æ¸›å°‘åˆ° {len(result)}")
        logger.debug(f"ğŸ”§ [å»é‡] åŸæ–‡: '{text[:50]}...'")
        logger.debug(f"ğŸ”§ [å»é‡] çµæœ: '{result[:50]}...'")

    return result


def _remove_ngram_repetitions(text: str, n: int) -> str:
    """
    ç§»é™¤æŒ‡å®šé•·åº¦çš„ n-gram é‡è¤‡

    Args:
        text: æ–‡æœ¬
        n: n-gram é•·åº¦

    Returns:
        str: è™•ç†å¾Œçš„æ–‡æœ¬
    """
    if len(text) < n * 2:
        return text

    # ä½¿ç”¨æ»‘å‹•çª—å£æª¢æ¸¬é‡è¤‡æ¨¡å¼
    i = 0
    result = []

    while i < len(text):
        if i + n * 2 <= len(text):
            # æå–ç•¶å‰ n-gram
            ngram = text[i:i+n]
            next_ngram = text[i+n:i+n*2]

            # æª¢æŸ¥æ˜¯å¦é‡è¤‡
            if ngram == next_ngram and len(ngram.strip()) > 0:
                # æ‰¾åˆ°é‡è¤‡æ¨¡å¼ï¼Œè·³éé‡è¤‡éƒ¨åˆ†
                result.append(ngram)
                # è·³éæ‰€æœ‰é€£çºŒçš„é‡è¤‡
                i += n
                while i + n <= len(text) and text[i:i+n] == ngram:
                    i += n
            else:
                result.append(text[i])
                i += 1
        else:
            result.append(text[i])
            i += 1

    return ''.join(result)


def _remove_chinese_repetitions(text: str) -> str:
    """
    ç§»é™¤ä¸­æ–‡ç‰¹æœ‰çš„ç–Šå­—æ¨¡å¼

    Args:
        text: æ–‡æœ¬

    Returns:
        str: è™•ç†å¾Œçš„æ–‡æœ¬
    """
    # è™•ç†é€£çºŒç›¸åŒä¸­æ–‡å­—ç¬¦ (å¦‚: "é€™é€™é€™å€‹" -> "é€™å€‹")
    result = re.sub(r'([\u4e00-\u9fff])\1{2,}', r'\1', text)

    # è™•ç†é€£çºŒç›¸åŒè©çµ„ (å¦‚: "é‚£å€‹é‚£å€‹" -> "é‚£å€‹")
    result = re.sub(r'(\w{2,})\s*\1\s*\1+', r'\1', result)

    # è™•ç†é€£çºŒç›¸åŒçŸ­èª (å¦‚: "å°±æ˜¯èªªå°±æ˜¯èªª" -> "å°±æ˜¯èªª")
    result = re.sub(r'([\u4e00-\u9fff]{2,4})\1{1,}', r'\1', result)

    return result


def postprocess_transcription_text(text: str, provider_name: str = "unknown") -> str:
    """
    è½‰éŒ„æ–‡æœ¬å¾Œè™•ç†ï¼šæ¸…ç†æ™‚é–“æˆ³ + å»é‡ + å“è³ªæª¢æŸ¥

    Args:
        text: åŸå§‹è½‰éŒ„æ–‡æœ¬
        provider_name: Provider åç¨±

    Returns:
        str: å¾Œè™•ç†çš„æ–‡æœ¬ï¼ˆå¦‚æœå“è³ªå¤ªå·®å‰‡è¿”å›ç©ºå­—ä¸²ï¼‰
    """
    if not text or not text.strip():
        return ""

    # 0. æ¸…ç†æ™‚é–“æˆ³æ¨™è¨˜
    cleaned_text = clean_timestamp_markers(text.strip())
    
    # 1. å»é™¤é‡è¤‡æ¨¡å¼
    deduplicated_text = remove_text_repetitions(cleaned_text)

    # 2. å“è³ªæª¢æŸ¥
    if not check_transcription_quality(deduplicated_text, provider_name):
        logger.info(f"ğŸ”‡ [{provider_name}] å¾Œè™•ç†å“è³ªæª¢æŸ¥å¤±æ•—ï¼Œè¿”å›ç©ºæ–‡æœ¬")
        return ""

    return deduplicated_text


def clean_timestamp_markers(text: str) -> str:
    """
    æ¸…ç†è½‰éŒ„æ–‡æœ¬ä¸­çš„æ™‚é–“æˆ³æ¨™è¨˜
    
    æ”¯æ´çš„æ ¼å¼ï¼š
    - <|5.59|> (Whisper æ ¼å¼)
    - [00:05.59] (SRT æ ¼å¼)
    - (5.59) (å…¶ä»–æ ¼å¼)
    
    Args:
        text: åŒ…å«æ™‚é–“æˆ³æ¨™è¨˜çš„æ–‡æœ¬
        
    Returns:
        str: æ¸…ç†å¾Œçš„æ–‡æœ¬
    """
    if not text:
        return ""
    
    # åŸå§‹æ–‡æœ¬ç”¨æ–¼æ¯”å°
    original_text = text
    
    # 1. æ¸…ç† Whisper æ ¼å¼æ™‚é–“æˆ³: <|æ•¸å­—|>
    text = re.sub(r'<\|\d+\.?\d*\|>', '', text)
    
    # 2. æ¸…ç† SRT æ ¼å¼æ™‚é–“æˆ³: [æ™‚:åˆ†.ç§’]
    text = re.sub(r'\[\d{2}:\d{2}\.\d{2}\]', '', text)
    
    # 3. æ¸…ç†æ‹¬è™Ÿæ ¼å¼æ™‚é–“æˆ³: (æ•¸å­—.æ•¸å­—)
    text = re.sub(r'\(\d+\.?\d*\)', '', text)
    
    # 4. æ¸…ç†å…¶ä»–å¯èƒ½çš„æ™‚é–“æˆ³æ ¼å¼
    text = re.sub(r'<\d+\.?\d*>', '', text)  # <5.59>
    text = re.sub(r'\|\d+\.?\d*\|', '', text)  # |5.59|
    
    # 5. æ¸…ç†å¤šé¤˜çš„ç©ºç™½
    text = re.sub(r'\s+', ' ', text).strip()
    
    # å¦‚æœæœ‰æ¸…ç†å‹•ä½œï¼Œè¨˜éŒ„æ—¥èªŒ
    if text != original_text:
        logger.debug(f"ğŸ§¹ [æ™‚é–“æˆ³æ¸…ç†] '{original_text[:50]}...' -> '{text[:50]}...'")
    
    return text


def check_transcription_quality(
    text: str,
    provider_name: str = "unknown"
) -> bool:
    """
    çµ±ä¸€çš„è½‰éŒ„å“è³ªæª¢æŸ¥å…¥å£

    Args:
        text: è½‰éŒ„æ–‡æœ¬
        provider_name: Provider åç¨±ï¼ˆç”¨æ–¼æ—¥èªŒï¼‰

    Returns:
        bool: True è¡¨ç¤ºå“è³ªè‰¯å¥½ï¼ŒFalse è¡¨ç¤ºæ‡‰è©²éæ¿¾
    """
    if is_low_quality_text(text):
        logger.info(f"ğŸ”‡ [{provider_name}] æ–‡æœ¬å“è³ªæª¢æŸ¥å¤±æ•—ï¼Œå»ºè­°éæ¿¾: '{text[:30]}...'")
        return False

    logger.debug(f"âœ… [{provider_name}] æ–‡æœ¬å“è³ªæª¢æŸ¥é€šé: '{text[:50]}...'")
    return True
