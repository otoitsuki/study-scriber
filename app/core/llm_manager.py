"""
LLM é…ç½®ç®¡ç†å™¨ - ä½¿ç”¨è¨˜æ†¶é«”å¿«å–
ä¸éœ€è¦ä¿®æ”¹è³‡æ–™åº«æ¶æ§‹ï¼Œæ”¯æ´ session ç´šåˆ¥çš„å‹•æ…‹ LLM é…ç½®
"""
from typing import Dict, Optional, Union
from uuid import UUID
from datetime import datetime, timedelta
from dataclasses import dataclass
import logging
from openai import AsyncOpenAI, AsyncAzureOpenAI

from app.core.config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


@dataclass
class LLMConfig:
    """LLM é…ç½®è³‡æ–™çµæ§‹"""
    base_url: str
    api_key: str
    model: str
    api_version: Optional[str] = None
    created_at: datetime = None

    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.utcnow()


class LLMConfigManager:
    """
    Session ç´š LLM é…ç½®ç®¡ç†å™¨
    ä½¿ç”¨è¨˜æ†¶é«”å¿«å–ï¼Œä¸ä¿®æ”¹è³‡æ–™åº«
    """

    def __init__(self, ttl_hours: int = 24):
        self._cache: Dict[UUID, LLMConfig] = {}
        self._ttl_hours = ttl_hours
        logger.info(f"LLMConfigManager initialized with TTL: {ttl_hours} hours")

    def set_config(self, session_id: UUID, config: dict) -> None:
        """å„²å­˜ session çš„ LLM é…ç½®"""
        self._cache[session_id] = LLMConfig(
            base_url=config["base_url"],
            api_key=config["api_key"],  # TODO: å¯¦éš›æ‡‰ç”¨æ‡‰åŠ å¯†
            model=config["model"],
            api_version=config.get("api_version")
        )
        logger.info(f"âœ… Set LLM config for session {session_id}, model: {config['model']}")

    def get_config(self, session_id: UUID) -> Optional[LLMConfig]:
        """å–å¾— session çš„ LLM é…ç½®ï¼Œæª¢æŸ¥éæœŸæ™‚é–“"""
        if session_id in self._cache:
            config = self._cache[session_id]
            # æª¢æŸ¥æ˜¯å¦éæœŸ
            if datetime.utcnow() - config.created_at < timedelta(hours=self._ttl_hours):
                return config
            else:
                # éæœŸå‰‡åˆªé™¤
                del self._cache[session_id]
                logger.info(f"â° Expired LLM config for session {session_id}")
        return None

    def clear_config(self, session_id: UUID) -> None:
        """æ¸…é™¤ç‰¹å®š session çš„é…ç½®"""
        if session_id in self._cache:
            del self._cache[session_id]
            logger.info(f"ğŸ—‘ï¸ Cleared LLM config for session {session_id}")

    def get_cache_stats(self) -> dict:
        """å–å¾—å¿«å–çµ±è¨ˆè³‡è¨Š"""
        active_configs = len(self._cache)
        return {
            "active_sessions": active_configs,
            "memory_usage_estimate_kb": active_configs * 1  # ç´„ 1KB per config
        }

    def detect_stt_method(self, model: str) -> str:
        """æ ¹æ“šæ¨¡å‹åç¨±åˆ¤æ–· STT æ–¹æ³•"""
        model_lower = model.lower()

        if "breeze-asr" in model_lower:
            return "localhost-whisper"
        elif "whisper" in model_lower:
            return "whisper"
        elif "gpt-4o" in model_lower or "gpt4o" in model_lower:
            return "gpt4o-audio"
        elif "gemini" in model_lower:
            return "gemini"
        else:
            # é è¨­ä½¿ç”¨ whisper APIï¼ˆå¤§éƒ¨åˆ† OpenAI ç›¸å®¹æœå‹™éƒ½æ”¯æ´ï¼‰
            logger.info(f"Unknown model {model}, defaulting to whisper API")
            return "whisper"

    def detect_provider_type(self, base_url: str) -> str:
        """æ ¹æ“š base_url åˆ¤æ–· provider é¡å‹"""
        base_url_lower = base_url.lower()

        if "openai.azure.com" in base_url_lower:
            return "azure"
        elif "api.openai.com" in base_url_lower:
            return "openai"
        elif "localhost" in base_url_lower or "127.0.0.1" in base_url_lower:
            return "local"
        else:
            return "openai_compatible"

    async def create_client(
        self,
        session_id: UUID
    ) -> Optional[Union[AsyncOpenAI, AsyncAzureOpenAI]]:
        """ç‚º session å»ºç«‹ LLM å®¢æˆ¶ç«¯"""

        # 1. å˜—è©¦å¾å¿«å–å–å¾—é…ç½®
        config = self.get_config(session_id)

        if config:
            logger.info(f"ğŸ”§ Creating LLM client for session {session_id} with model {config.model}")

            # åˆ¤æ–· provider é¡å‹
            provider_type = self.detect_provider_type(config.base_url)

            if provider_type == "azure":
                return AsyncAzureOpenAI(
                    api_key=config.api_key,
                    azure_endpoint=config.base_url,
                    api_version=config.api_version or "2024-06-01",
                    timeout=(5, 55),
                    max_retries=2
                )
            else:
                # OpenAI æ¨™æº–æˆ–ç›¸å®¹ API
                return AsyncOpenAI(
                    api_key=config.api_key,
                    base_url=config.base_url,
                    timeout=(5, 55),
                    max_retries=2
                )

        # 2. Fallback åˆ°ç’°å¢ƒè®Šæ•¸ï¼ˆä¿æŒå‘å¾Œç›¸å®¹ï¼‰
        logger.info(f"ğŸ“¦ No session config found for {session_id}, falling back to environment variables")

        if settings.AZURE_OPENAI_API_KEY and settings.AZURE_OPENAI_ENDPOINT:
            logger.info("Using Azure OpenAI from environment variables")
            return AsyncAzureOpenAI(
                api_key=settings.AZURE_OPENAI_API_KEY,
                azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
                api_version="2024-06-01",
                timeout=(5, 55),
                max_retries=2
            )

        logger.warning(f"âŒ No LLM configuration available for session {session_id}")
        return None

    def get_model_for_session(self, session_id: UUID) -> str:
        """å–å¾— session ä½¿ç”¨çš„æ¨¡å‹åç¨±"""
        config = self.get_config(session_id)
        if config:
            return config.model

        # Fallback åˆ°ç’°å¢ƒè®Šæ•¸
        stt_method = settings.STT_PROVIDER_DEFAULT
        if stt_method == "whisper":
            return settings.WHISPER_DEPLOYMENT_NAME or "whisper-1"
        elif stt_method == "gpt4o":
            return settings.GPT4O_DEPLOYMENT_NAME or "gpt-4o"

        return "whisper-1"  # é è¨­

    def mask_api_key(self, api_key: str) -> str:
        """é®ç½© API key ç”¨æ–¼æ—¥èªŒé¡¯ç¤º"""
        if not api_key or len(api_key) < 8:
            return "â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢"

        # é¡¯ç¤ºå‰ 3 ç¢¼å’Œå¾Œ 3 ç¢¼
        return f"{api_key[:3]}{'â€¢' * (len(api_key) - 6)}{api_key[-3:]}"


# å…¨åŸŸå¯¦ä¾‹
llm_manager = LLMConfigManager()

