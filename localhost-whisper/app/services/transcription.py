"""
MLX Whisper API è½‰éŒ„æœå‹™

å¯¦ä½œéŸ³æª”è½‰éŒ„çš„æ ¸å¿ƒé‚è¼¯ï¼ŒåŒ…æ‹¬éŸ³æª”è™•ç†ã€
MLX Whisper æ¨¡å‹èª¿ç”¨ã€çµæœæ ¼å¼åŒ–ç­‰åŠŸèƒ½ã€‚
"""

import asyncio
import io
import logging
import os
import time
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Optional, Any, Tuple, Union

import librosa
import numpy as np
import mlx_whisper

from app.config import get_settings
from app.models.schemas import (
    TranscriptionResponse,
    SegmentInfo,
    WordInfo,
    TimestampGranularity,
    ProcessingStats,
    AudioFileInfo,
)
from app.services.model_manager import get_model_manager


logger = logging.getLogger(__name__)


class TranscriptionError(Exception):
    """è½‰éŒ„éŒ¯èª¤ç•°å¸¸"""

    pass


class AudioProcessingError(Exception):
    """éŸ³æª”è™•ç†éŒ¯èª¤ç•°å¸¸"""

    pass


class TranscriptionService:
    """è½‰éŒ„æœå‹™"""

    def __init__(self):
        """åˆå§‹åŒ–è½‰éŒ„æœå‹™"""
        self.settings = get_settings()
        self.model_manager = get_model_manager()

        # éŸ³æª”è™•ç†åŸ·è¡Œç·’æ± 
        self._audio_executor = ThreadPoolExecutor(
            max_workers=4, thread_name_prefix="audio_processor"
        )

        # è½‰éŒ„åŸ·è¡Œç·’æ± 
        self._transcription_executor = ThreadPoolExecutor(
            max_workers=self.settings.max_concurrent_per_worker,
            thread_name_prefix="mlx_transcriber",
        )

        # çµ±è¨ˆè³‡è¨Š
        self._stats = {
            "total_transcriptions": 0,
            "total_audio_duration": 0.0,
            "total_processing_time": 0.0,
            "failed_transcriptions": 0,
        }

        logger.info("è½‰éŒ„æœå‹™å·²åˆå§‹åŒ–")

    async def get_service_status(self) -> Dict[str, Any]:
        """
        ç²å–è½‰éŒ„æœå‹™ç‹€æ…‹

        Returns:
            Dict: æœå‹™ç‹€æ…‹è³‡è¨Š
        """
        return {
            "available": True,
            "active_requests": 0,  # é€™è£¡å¯ä»¥æ ¹æ“šå¯¦éš›æƒ…æ³å¯¦ç¾
            "max_concurrent": self.settings.max_concurrent_per_worker,
            "stats": self.get_stats(),
        }

    async def transcribe_audio(
        self,
        audio_data: bytes,
        model_name: str,
        language: Optional[str] = None,
        prompt: Optional[str] = None,
        temperature: float = 0.0,
        timestamp_granularities: Optional[List[TimestampGranularity]] = None,
        content_type: Optional[str] = None,
        filename: Optional[str] = None,
    ) -> TranscriptionResponse:
        """
        è½‰éŒ„éŸ³æª”

        Args:
            audio_data: éŸ³æª”äºŒé€²ä½è³‡æ–™
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç¨±
            language: éŸ³æª”èªè¨€
            prompt: å¼•å°æ–‡å­—
            temperature: å–æ¨£æº«åº¦
            timestamp_granularities: æ™‚é–“æˆ³ç²¾åº¦
            content_type: æª”æ¡ˆMIMEé¡å‹
            filename: æª”æ¡ˆåç¨±

        Returns:
            TranscriptionResponse: è½‰éŒ„çµæœ

        Raises:
            TranscriptionError: è½‰éŒ„å¤±æ•—
            AudioProcessingError: éŸ³æª”è™•ç†å¤±æ•—
        """
        start_time = time.time()

        try:
            logger.info(
                f"é–‹å§‹è½‰éŒ„: model={model_name}, language={language}, "
                f"temp={temperature}, filename={filename}"
            )

            # 1. é è™•ç†éŸ³æª”
            audio_info = await self._process_audio(audio_data, content_type, filename)

            # 2. é©—è­‰æ¨¡å‹åç¨±
            model_load_start = time.time()
            verified_model_name = await self.model_manager.get_model(model_name)
            model_load_time = time.time() - model_load_start

            # 3. åŸ·è¡Œè½‰éŒ„
            result = await self._execute_transcription(
                audio_info.audio_array,  # <-- æˆ‘å€‘éœ€è¦ audio_array
                verified_model_name,  # <-- å‚³éæ¨¡å‹åç¨±å­—ä¸²
                language,
                prompt,
                temperature,
                timestamp_granularities,
            )

            # 4. å»ºæ§‹å›æ‡‰
            total_processing_time = time.time() - start_time

            response = TranscriptionResponse(
                text=result["text"].strip(),
                task="transcribe",
                language=result.get("language", language or "unknown"),
                duration=audio_info.duration,
                segments=result.get("segments"),
                words=result.get("words"),
            )

            # 5. æ›´æ–°çµ±è¨ˆ
            self._update_stats(
                total_processing_time, audio_info.duration or 0, success=True
            )

            logger.info(
                f"è½‰éŒ„å®Œæˆ: è™•ç†æ™‚é–“={total_processing_time:.2f}s, "
                f"éŸ³æª”é•·åº¦={audio_info.duration:.2f}s, "
                f"é€Ÿåº¦æ¯”ç‡={((audio_info.duration or 0) / total_processing_time):.2f}x"
            )

            return response

        except Exception as e:
            # æ›´æ–°å¤±æ•—çµ±è¨ˆ
            self._update_stats(0, 0, success=False)

            logger.error(f"è½‰éŒ„å¤±æ•—: {str(e)}", exc_info=True)

            if isinstance(e, (TranscriptionError, AudioProcessingError)):
                raise
            else:
                raise TranscriptionError(f"è½‰éŒ„éç¨‹ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {str(e)}")

    async def _process_audio(
        self,
        audio_data: bytes,
        content_type: Optional[str] = None,
        filename: Optional[str] = None,
    ) -> AudioFileInfo:
        """
        è™•ç†éŸ³æª”ï¼Œè¼‰å…¥ä¸¦è½‰æ›ç‚ºé©åˆçš„æ ¼å¼

        Args:
            audio_data: éŸ³æª”äºŒé€²ä½è³‡æ–™
            content_type: MIMEé¡å‹
            filename: æª”æ¡ˆåç¨±

        Returns:
            AudioFileInfo: è™•ç†å¾Œçš„éŸ³æª”è³‡è¨Š

        Raises:
            AudioProcessingError: éŸ³æª”è™•ç†å¤±æ•—
        """
        try:
            logger.debug(
                f"é–‹å§‹è™•ç†éŸ³æª”: size={len(audio_data)}bytes, "
                f"type={content_type}, name={filename}"
            )

            # åœ¨åŸ·è¡Œç·’æ± ä¸­è™•ç†éŸ³æª”ï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç’°ï¼‰
            loop = asyncio.get_event_loop()
            audio_array, sample_rate, duration = await loop.run_in_executor(
                self._audio_executor, self._load_audio_sync, audio_data
            )

            # å»ºç«‹éŸ³æª”è³‡è¨Š
            audio_info = AudioFileInfo(
                filename=filename or "unknown.audio",
                size=len(audio_data),
                content_type=content_type or "application/octet-stream",
                duration=duration,
                sample_rate=sample_rate,
                channels=1,  # librosa å·²è½‰æ›ç‚ºå–®è²é“
            )

            # å°‡è™•ç†å¾Œçš„éŸ³æª”é™£åˆ—å„²å­˜åˆ° audio_infoï¼ˆç”¨æ–¼å¾ŒçºŒè½‰éŒ„ï¼‰
            audio_info.audio_array = audio_array

            logger.debug(
                f"éŸ³æª”è™•ç†å®Œæˆ: duration={duration:.2f}s, "
                f"sample_rate={sample_rate}Hz"
            )

            return audio_info

        except Exception as e:
            logger.error(f"éŸ³æª”è™•ç†å¤±æ•—: {str(e)}", exc_info=True)
            raise AudioProcessingError(f"ç„¡æ³•è™•ç†éŸ³æª”: {str(e)}")

    def _load_audio_sync(self, audio_data: bytes) -> Tuple[np.ndarray, int, float]:
        """
        åŒæ­¥è¼‰å…¥éŸ³æª”ï¼ˆåœ¨åŸ·è¡Œç·’æ± ä¸­åŸ·è¡Œï¼‰

        Args:
            audio_data: éŸ³æª”äºŒé€²ä½è³‡æ–™

        Returns:
            Tuple[np.ndarray, int, float]: éŸ³æª”é™£åˆ—ã€å–æ¨£ç‡ã€æ™‚é•·

        Raises:
            AudioProcessingError: è¼‰å…¥å¤±æ•—
        """
        try:
            # ä½¿ç”¨ librosa è¼‰å…¥éŸ³æª”
            audio_io = io.BytesIO(audio_data)

            # è¼‰å…¥ä¸¦è½‰æ›ç‚º Whisper éœ€è¦çš„æ ¼å¼
            audio_array, sample_rate = librosa.load(
                audio_io,
                sr=16000,  # Whisper ä½¿ç”¨ 16kHz
                mono=True,  # è½‰æ›ç‚ºå–®è²é“
                dtype=np.float32,
            )

            # è¨ˆç®—æ™‚é•·
            duration = len(audio_array) / sample_rate

            logger.debug(
                f"éŸ³æª”è¼‰å…¥æˆåŠŸ: shape={audio_array.shape}, "
                f"sr={sample_rate}, duration={duration:.2f}s"
            )

            return audio_array, sample_rate, duration

        except Exception as e:
            logger.error(f"éŸ³æª”è¼‰å…¥å¤±æ•—: {str(e)}")
            raise AudioProcessingError(f"ç„¡æ³•è¼‰å…¥éŸ³æª”: {str(e)}")

    def _is_audio_silent(self, audio_array: np.ndarray,
                        energy_threshold: float = 0.001,
                        silence_ratio_threshold: float = 0.9) -> bool:
        """
        æª¢æ¸¬éŸ³é »æ˜¯å¦ç‚ºéœéŸ³æˆ–ä½èƒ½é‡

        Args:
            audio_array: éŸ³é »é™£åˆ—
            energy_threshold: èƒ½é‡é–€æª»
            silence_ratio_threshold: éœéŸ³æ¯”ä¾‹é–€æª»

        Returns:
            bool: æ˜¯å¦ç‚ºéœéŸ³
        """
        try:
            # è¨ˆç®—éŸ³é »èƒ½é‡ï¼ˆRMSï¼‰
            energy = np.sqrt(np.mean(audio_array ** 2))

            # å¦‚æœæ•´é«”èƒ½é‡éä½ï¼Œç›´æ¥åˆ¤å®šç‚ºéœéŸ³
            if energy < energy_threshold:
                logger.debug(f"ğŸ”‡ [éœéŸ³æª¢æ¸¬] æ•´é«”èƒ½é‡éä½: {energy:.6f} < {energy_threshold}")
                return True

            # åˆ†æ®µæª¢æ¸¬éœéŸ³
            frame_length = int(0.1 * 16000)  # 100ms çª—å£
            hop_length = frame_length // 2

            silent_frames = 0
            total_frames = 0

            for i in range(0, len(audio_array) - frame_length, hop_length):
                frame = audio_array[i:i + frame_length]
                frame_energy = np.sqrt(np.mean(frame ** 2))

                total_frames += 1
                if frame_energy < energy_threshold:
                    silent_frames += 1

            silence_ratio = silent_frames / total_frames if total_frames > 0 else 1.0

            is_silent = silence_ratio >= silence_ratio_threshold
            logger.debug(
                f"ğŸ”‡ [éœéŸ³æª¢æ¸¬] èƒ½é‡: {energy:.6f}, éœéŸ³æ¯”ä¾‹: {silence_ratio:.2f}, "
                f"æ˜¯å¦éœéŸ³: {is_silent}"
            )

            return is_silent

        except Exception as e:
            logger.warning(f"éœéŸ³æª¢æ¸¬å¤±æ•—: {str(e)}")
            return False  # æª¢æ¸¬å¤±æ•—æ™‚é è¨­ç‚ºééœéŸ³ï¼Œé¿å…éåº¦éæ¿¾

    def _is_repetitive_text(self, text: str,
                          max_repetition_ratio: float = 0.6,
                          min_char_threshold: int = 3) -> bool:
        """
        æª¢æ¸¬æ–‡æœ¬æ˜¯å¦ç‚ºé‡è¤‡å­—ç¬¦æ¨¡å¼ï¼ˆå¹»è¦ºè¼¸å‡ºï¼‰
        (ç‚ºäº†ä¿æŒèˆ‡ç¾æœ‰é‚è¼¯çš„å…¼å®¹æ€§ï¼Œä¿ç•™æ­¤æ–¹æ³•)
        """
        # å°å…¥å…±ç”¨å·¥å…·å‡½æ•¸
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '../../..'))

        try:
            from app.utils.text_quality import is_repetitive_text
            return is_repetitive_text(text, max_repetition_ratio, min_char_threshold)
        except ImportError:
            # å¦‚æœç„¡æ³•å°å…¥å…±ç”¨å‡½æ•¸ï¼Œä½¿ç”¨æœ¬åœ°å¯¦ç¾ä½œç‚ºå‚™ç”¨
            logger.warning("ç„¡æ³•å°å…¥å…±ç”¨æ–‡æœ¬å“è³ªæª¢æŸ¥å‡½æ•¸ï¼Œä½¿ç”¨æœ¬åœ°å¯¦ç¾")
            return self._is_repetitive_text_local(text, max_repetition_ratio, min_char_threshold)

    def _is_repetitive_text_local(self, text: str,
                                max_repetition_ratio: float = 0.6,
                                min_char_threshold: int = 3) -> bool:
        """æœ¬åœ°å¯¦ç¾çš„é‡è¤‡æ–‡æœ¬æª¢æ¸¬ï¼ˆå‚™ç”¨ï¼‰"""
        try:
            if not text or len(text.strip()) < min_char_threshold:
                return True  # ç©ºæ–‡æœ¬æˆ–éçŸ­æ–‡æœ¬è¦–ç‚ºä½å“è³ª

            text = text.strip()

            # æª¢æ¸¬å–®å­—ç¬¦é‡è¤‡æ¨¡å¼
            char_counts = {}
            for char in text:
                if char.strip():  # å¿½ç•¥ç©ºç™½å­—ç¬¦
                    char_counts[char] = char_counts.get(char, 0) + 1

            if char_counts:
                # è¨ˆç®—æœ€é«˜é »å­—ç¬¦çš„æ¯”ä¾‹
                max_char_count = max(char_counts.values())
                repetition_ratio = max_char_count / len(text.replace(' ', ''))

                if repetition_ratio > max_repetition_ratio:
                    logger.debug(
                        f"ğŸ”„ [é‡è¤‡æª¢æ¸¬] é«˜é‡è¤‡æ¯”ä¾‹: {repetition_ratio:.2f} > {max_repetition_ratio}, "
                        f"æ–‡æœ¬: '{text[:20]}...'"
                    )
                    return True

            # æª¢æ¸¬å¸¸è¦‹çš„ Whisper å¹»è¦ºæ¨¡å¼
            hallucination_patterns = [
                r'^([ä¹–å—¯å‘ƒå•Šå“¦]{3,})',  # é‡è¤‡çš„ä¸­æ–‡å­—ç¬¦
                r'^([a-zA-Z])\1{4,}',      # é‡è¤‡çš„è‹±æ–‡å­—ç¬¦
                r'^(.{1,2})\1{3,}',       # çŸ­æ¨¡å¼é‡è¤‡
                r'(è¬è¬è§€çœ‹|è¬è¬æ”¶è½|è¬è¬|æ„Ÿè¬|Subscribe)',  # å¸¸è¦‹çš„å¹»è¦ºçŸ­èª
            ]

            import re
            for pattern in hallucination_patterns:
                if re.search(pattern, text):
                    logger.debug(f"ğŸ”„ [æ¨¡å¼æª¢æ¸¬] æª¢æ¸¬åˆ°å¹»è¦ºæ¨¡å¼: '{text[:20]}...'")
                    return True

            return False

        except Exception as e:
            logger.warning(f"é‡è¤‡æ–‡æœ¬æª¢æ¸¬å¤±æ•—: {str(e)}")
            return False  # æª¢æ¸¬å¤±æ•—æ™‚é è¨­ç‚ºéé‡è¤‡

    def _filter_transcription_result(self, result: Dict[str, Any], audio_array: np.ndarray) -> Optional[Dict[str, Any]]:
        """
        éæ¿¾è½‰éŒ„çµæœï¼Œç§»é™¤ä½å“è³ªè¼¸å‡º

        Args:
            result: è½‰éŒ„çµæœ
            audio_array: éŸ³é »é™£åˆ—

        Returns:
            éæ¿¾å¾Œçš„çµæœï¼Œå¦‚æœæ‡‰è©²è¢«éæ¿¾å‰‡è¿”å› None
        """
        try:
            # 1. æª¢æŸ¥éŸ³é »æ˜¯å¦ç‚ºéœéŸ³
            if self._is_audio_silent(audio_array):
                logger.info("ğŸ”‡ [å“è³ªéæ¿¾] éŸ³é »ç‚ºéœéŸ³ï¼Œéæ¿¾è½‰éŒ„çµæœ")
                return None

            # 2. æª¢æŸ¥æ–‡æœ¬å“è³ª
            text = result.get("text", "").strip()
            if not text:
                logger.info("ğŸ”‡ [å“è³ªéæ¿¾] è½‰éŒ„çµæœç‚ºç©ºï¼Œéæ¿¾")
                return None

            # 3. æª¢æ¸¬é‡è¤‡æ¨¡å¼
            if self._is_repetitive_text(text):
                logger.info(f"ğŸ”„ [å“è³ªéæ¿¾] æª¢æ¸¬åˆ°é‡è¤‡æ¨¡å¼ï¼Œéæ¿¾: '{text[:30]}...'")
                return None

            # 4. æª¢æŸ¥æ–‡æœ¬é•·åº¦åˆç†æ€§
            if len(text) > 500:  # 15ç§’éŸ³é »ä¸æ‡‰è©²ç”¢ç”Ÿéé•·æ–‡æœ¬
                logger.warning(f"ğŸ”‡ [å“è³ªéæ¿¾] æ–‡æœ¬éé•·ï¼Œå¯èƒ½ç‚ºå¹»è¦º: {len(text)} å­—ç¬¦")
                return None

            logger.debug(f"âœ… [å“è³ªéæ¿¾] è½‰éŒ„çµæœé€šéå“è³ªæª¢æŸ¥: '{text[:50]}...'")
            return result

        except Exception as e:
            logger.warning(f"å“è³ªéæ¿¾å¤±æ•—: {str(e)}")
            return result  # éæ¿¾å¤±æ•—æ™‚è¿”å›åŸçµæœ

    async def _execute_transcription(
        self,
        audio_array: np.ndarray,  # <--- æ¥æ”¶ audio_array
        model_name: str,  # <--- æ¥æ”¶æ¨¡å‹åç¨±
        language: Optional[str] = None,
        prompt: Optional[str] = None,
        temperature: float = 0.0,
        timestamp_granularities: Optional[List[TimestampGranularity]] = None,
    ) -> Dict[str, Any]:
        """
        åŸ·è¡Œ MLX Whisper è½‰éŒ„

        Args:
            audio_array: é è™•ç†çš„éŸ³æª”é™£åˆ—
            model_name: æ¨¡å‹åç¨±
            language: èªè¨€
            prompt: å¼•å°æ–‡å­—
            temperature: æº«åº¦
            timestamp_granularities: æ™‚é–“æˆ³ç²¾åº¦

        Returns:
            Dict: è½‰éŒ„çµæœ

        Raises:
            TranscriptionError: è½‰éŒ„å¤±æ•—
        """
        try:
            # åœ¨åŸ·è¡Œç·’æ± ä¸­åŸ·è¡Œè½‰éŒ„ï¼ˆMLX Whisper æ˜¯åŒæ­¥çš„ï¼‰
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self._transcription_executor,
                self._transcribe_sync,
                audio_array,
                model_name,  # <-- å‚³éæ¨¡å‹åç¨±
                language,
                prompt,
                temperature,
                timestamp_granularities,
            )

            return result

        except Exception as e:
            logger.error(f"MLX Whisper è½‰éŒ„å¤±æ•—: {str(e)}", exc_info=True)
            raise TranscriptionError(f"è½‰éŒ„åŸ·è¡Œå¤±æ•—: {str(e)}")

    def _transcribe_sync(
        self,
        audio_array: np.ndarray,
        model_name: str,  # <--- æ¥æ”¶æ¨¡å‹åç¨±
        language: Optional[str] = None,
        prompt: Optional[str] = None,
        temperature: float = 0.0,
        timestamp_granularities: Optional[List[TimestampGranularity]] = None,
    ) -> Dict[str, Any]:
        """
        åŒæ­¥åŸ·è¡Œ MLX Whisper è½‰éŒ„

        Args:
            audio_array: é è™•ç†çš„éŸ³æª”é™£åˆ—
            model_name: æ¨¡å‹åç¨±
            language: èªè¨€
            prompt: å¼•å°æ–‡å­—
            temperature: æº«åº¦
            timestamp_granularities: æ™‚é–“æˆ³ç²¾åº¦

        Returns:
            Dict: è½‰éŒ„çµæœ
        """
        try:
            # æº–å‚™ MLX Whisper åƒæ•¸
            transcribe_options = {"verbose": False}

            # è¨­å®šèªè¨€
            if language and language != "auto":
                transcribe_options["language"] = language

            # è¨­å®šå¼•å°æ–‡å­—
            # å°ä¸­æ–‡æ·»åŠ ç¹é«”ä¸­æ–‡å¼•å°ï¼Œç¢ºä¿è¼¸å‡ºç¹é«”ä¸­æ–‡è€Œéç°¡é«”ä¸­æ–‡
            traditional_chinese_prompt = ""
            if language and language.lower() in ["zh", "chinese", "zh-tw", "zh-cn"]:
                traditional_chinese_prompt = "ä»¥ä¸‹æ˜¯ç¹é«”ä¸­æ–‡çš„å¥å­ã€‚"

            if prompt:
                if traditional_chinese_prompt:
                    transcribe_options["initial_prompt"] = f"{traditional_chinese_prompt} {prompt}"
                else:
                    transcribe_options["initial_prompt"] = prompt
            elif traditional_chinese_prompt:
                transcribe_options["initial_prompt"] = traditional_chinese_prompt

            # è¨­å®šæº«åº¦ï¼ˆé™ä½æº«åº¦æ¸›å°‘å¹»è¦ºï¼‰
            transcribe_options["temperature"] = max(0.0, min(temperature, 0.2))

            # ===============================
            # é˜²ç–Šå­—æ ¸å¿ƒåƒæ•¸è¨­å®š
            # ===============================
            # æ³¨æ„ï¼šMLX Whisper ä¸æ”¯æ´ no_repeat_ngram_size å’Œ repetition_penalty åƒæ•¸
            # æ”¹ç”¨å…¶ä»–æ–¹å¼ä¾†æ¸›å°‘é‡è¤‡

            # 1. Beam search è¨­å®šï¼ˆæå‡è§£ç¢¼å“è³ªï¼‰
            # æ³¨æ„ï¼šç•¶å‰ç‰ˆæœ¬çš„ MLX Whisper ä¸æ”¯æ´ beam searchï¼Œæš«æ™‚ç§»é™¤
            # transcribe_options["beam_size"] = 5  # ä½¿ç”¨ beam search
            # transcribe_options["best_of"] = 3    # å¾å¤šå€‹å€™é¸ä¸­é¸æœ€ä½³

            # 2. é•·åº¦æ‡²ç½°ï¼ˆé¿å…éçŸ­æˆ–éé•·è¼¸å‡ºï¼‰
            transcribe_options["length_penalty"] = 1.0

            # ===============================
            # æŠ‘åˆ¶å¹»è¦º Token è¨­å®š
            # ===============================

            # æ·»åŠ  suppress_tokens ä¾†æŠ‘åˆ¶å¸¸è¦‹çš„å¹»è¦º token
            suppress_tokens = [
                # å¸¸è¦‹çš„é‡è¤‡å­—ç¬¦å’Œç„¡æ„ç¾©éŸ³ç´ 
                50257,  # <endoftext>
                50362,  # (music)
                50363,  # (applause)
                50364,  # (laughter)
                50365,  # [BLANK_AUDIO]
                # å¯ä»¥æ ¹æ“šéœ€è¦æ·»åŠ æ›´å¤š token
            ]

            # å°æ–¼ä¸­æ–‡ï¼Œæ·»åŠ é¡å¤–çš„æŠ‘åˆ¶ç­–ç•¥
            if language and language.lower() in ["zh", "chinese", "zh-tw", "zh-cn"]:
                # ä¸­æ–‡å¸¸è¦‹å¹»è¦ºæ¨¡å¼çš„é¡å¤–æŠ‘åˆ¶
                # é€™äº› token ID å¯èƒ½éœ€è¦æ ¹æ“šå¯¦éš›è§€å¯Ÿåˆ°çš„å¹»è¦ºé€²è¡Œèª¿æ•´
                chinese_hallucination_tokens = [
                    # å¯ä»¥æ ¹æ“šè§€å¯Ÿåˆ°çš„ç‰¹å®šå¹»è¦ºæ¨¡å¼æ·»åŠ å°æ‡‰çš„ token ID
                ]
                suppress_tokens.extend(chinese_hallucination_tokens)

                logger.debug(f"ğŸ‡¹ğŸ‡¼ ç‚ºä¸­æ–‡æ¨¡å¼æ·»åŠ é¡å¤–å¹»è¦ºæŠ‘åˆ¶ tokens: {len(chinese_hallucination_tokens)} å€‹")

            transcribe_options["suppress_tokens"] = suppress_tokens

            # ===============================
            # å“è³ªæ§åˆ¶åƒæ•¸
            # ===============================

            # è¨­å®šå…¶ä»–åƒæ•¸ä¾†æ¸›å°‘å¹»è¦º
            transcribe_options["no_speech_threshold"] = 0.4     # æé«˜éœéŸ³æª¢æ¸¬é–€æª»
            transcribe_options["logprob_threshold"] = -0.8      # æé«˜ç½®ä¿¡åº¦é–€æª»
            transcribe_options["compression_ratio_threshold"] = 2.0  # é™ä½é‡è¤‡å…§å®¹é–€æª»ï¼ˆæ›´åš´æ ¼ï¼‰

            # æ¢ä»¶ç†µè¨­å®šï¼ˆMLX Whisper æ”¯æ´æ­¤åƒæ•¸ï¼‰
            transcribe_options["condition_on_previous_text"] = False  # ä¸ä¾è³´å‰æ–‡ï¼Œæ¸›å°‘ç´¯ç©éŒ¯èª¤

            # è¨­å®šæ™‚é–“æˆ³
            # æ ¹æ“šè«‹æ±‚çš„ granularities æ±ºå®šæ˜¯å¦å•Ÿç”¨ word_timestamps
            granularities_set = set(timestamp_granularities or [])
            if TimestampGranularity.WORD in granularities_set:
                transcribe_options["word_timestamps"] = True
            elif (
                TimestampGranularity.SEGMENT in granularities_set
                or not granularities_set
            ):
                # å°æ–¼ segment æˆ–é è¨­æƒ…æ³ï¼Œä¸å•Ÿç”¨ word_timestamps ä»¥æå‡æ•ˆèƒ½
                transcribe_options["word_timestamps"] = False

            logger.debug(f"é–‹å§‹ MLX Whisper è½‰éŒ„: options={transcribe_options}")

            # è¨˜éŒ„ç¹é«”ä¸­æ–‡å¼•å°ç‹€æ…‹
            if "initial_prompt" in transcribe_options:
                logger.info(f"ä½¿ç”¨å¼•å°æ–‡å­—ç¢ºä¿ç¹é«”ä¸­æ–‡è¼¸å‡º: {transcribe_options['initial_prompt'][:30]}...")

            # å–å¾—æ¨¡å‹è³‡è¨Šï¼Œæ±ºå®šä½¿ç”¨æœ¬åœ°è·¯å¾‘é‚„æ˜¯ HuggingFace repo
            model_info = self.settings.get_model_info(model_name)
            if model_info and model_info.get("hf_repo"):
                # ä½¿ç”¨ HuggingFace repo
                path_or_hf_repo = model_info["hf_repo"]
                logger.debug(f"ä½¿ç”¨ HuggingFace æ¨¡å‹: {path_or_hf_repo}")
            else:
                # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾‘
                path_or_hf_repo = os.path.join(
                    self.settings.model_cache_dir, model_name
                )
                logger.debug(f"ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾‘: {path_or_hf_repo}")

            # åŸ·è¡Œè½‰éŒ„
            result = mlx_whisper.transcribe(
                audio_array, path_or_hf_repo=path_or_hf_repo, **transcribe_options
            )

            # èª¿è©¦ï¼šè¨˜éŒ„åŸå§‹çµæœçµæ§‹
            logger.debug(f"MLX Whisper åŸå§‹çµæœé¡å‹: {type(result)}")
            logger.debug(
                f"MLX Whisper åŸå§‹çµæœéµå€¼: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}"
            )
            if isinstance(result, dict):
                logger.debug(
                    f"MLX Whisper segments é¡å‹: {type(result.get('segments'))}"
                )
                logger.debug(f"MLX Whisper segments å…§å®¹: {result.get('segments')}")
                logger.debug(
                    f"MLX Whisper text å…§å®¹: {result.get('text', '')[:100]}..."
                )

            # è™•ç†çµæœ
            processed_result = self._process_transcription_result(
                result, timestamp_granularities
            )

            # å“è³ªéæ¿¾å’Œå¾Œè™•ç†
            filtered_result = self._filter_transcription_result(processed_result, audio_array)
            if filtered_result is None:
                # è¿”å›ç©ºçµæœè¡¨ç¤ºè¢«éæ¿¾
                logger.info("ğŸ”‡ [Whisper] è½‰éŒ„çµæœè¢«å“è³ªéæ¿¾å™¨éæ¿¾")
                return {
                    "text": "",
                    "language": result.get("language", "unknown"),
                    "segments": [],
                    "words": [],
                    "_filtered": True  # æ¨™è¨˜ç‚ºå·²éæ¿¾
                }

            # æ‡‰ç”¨å¾Œè™•ç†å»é‡
            if filtered_result.get("text"):
                try:
                    # å°å…¥å¾Œè™•ç†å‡½æ•¸
                    import sys
                    import os
                    sys.path.append(os.path.join(os.path.dirname(__file__), '../../../'))
                    from app.utils.text_quality import postprocess_transcription_text

                    original_text = filtered_result["text"]
                    processed_text = postprocess_transcription_text(original_text, "MLX-Whisper")

                    if processed_text != original_text:
                        logger.info(f"ğŸ”§ [å¾Œè™•ç†] æ–‡æœ¬å»é‡å®Œæˆ: '{original_text[:30]}...' -> '{processed_text[:30]}...'")
                        filtered_result["text"] = processed_text

                        # å¦‚æœå¾Œè™•ç†å¾Œæ–‡æœ¬ç‚ºç©ºï¼Œæ¨™è¨˜ç‚ºéæ¿¾
                        if not processed_text.strip():
                            logger.info("ğŸ”‡ [å¾Œè™•ç†] å»é‡å¾Œæ–‡æœ¬ç‚ºç©ºï¼Œæ¨™è¨˜ç‚ºéæ¿¾")
                            return {
                                "text": "",
                                "language": result.get("language", "unknown"),
                                "segments": [],
                                "words": [],
                                "_filtered": True,
                                "_postprocessed": True
                            }

                except ImportError as e:
                    logger.warning(f"ç„¡æ³•å°å…¥å¾Œè™•ç†å‡½æ•¸ï¼Œè·³éå»é‡æ­¥é©Ÿ: {e}")
                except Exception as e:
                    logger.error(f"å¾Œè™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
                    # ç™¼ç”ŸéŒ¯èª¤æ™‚ä½¿ç”¨åŸå§‹çµæœ

            logger.debug(
                f"MLX Whisper è½‰éŒ„å®Œæˆï¼Œæ–‡å­—é•·åº¦: {len(filtered_result['text'])}, segments_count: {len(filtered_result['segments'])}"
            )

            return filtered_result

        except Exception as e:
            logger.error(f"åŒæ­¥è½‰éŒ„å¤±æ•—: {str(e)}")
            raise TranscriptionError(f"MLX Whisper è½‰éŒ„å¤±æ•—: {str(e)}")

    def _process_transcription_result(
        self,
        result: Dict[str, Any],
        timestamp_granularities: Optional[List[TimestampGranularity]] = None,
    ) -> Dict[str, Any]:
        """
        è™•ç†è½‰éŒ„çµæœï¼Œæ ¼å¼åŒ–ç‚ºçµ±ä¸€çš„å›æ‡‰æ ¼å¼
        """
        try:
            processed = {
                "text": result.get("text", "").strip(),
                "language": result.get("language", "unknown"),
                "segments": [],
                "words": [],
            }

            # ç¢ºä¿ timestamp_granularities æ˜¯ä¸€å€‹é›†åˆä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾
            granularities_set = set(timestamp_granularities or [])

            # è™•ç†æ®µè½è³‡è¨Š
            # æ³¨æ„ï¼šå³ä½¿åªè«‹æ±‚ wordï¼Œæˆ‘å€‘ä¹Ÿé€šå¸¸æœƒå›å‚³ segmentï¼Œé€™ç¬¦åˆ OpenAI è¡Œç‚º
            # å¦‚æœæ²’æœ‰æŒ‡å®š granularitiesï¼Œé è¨­åŒ…å« segments
            should_include_segments = (
                TimestampGranularity.SEGMENT in granularities_set
                or TimestampGranularity.WORD in granularities_set
                or not granularities_set  # å¦‚æœæ²’æœ‰æŒ‡å®šï¼Œé è¨­åŒ…å«
            )

            if should_include_segments and result.get("segments"):
                segments = []
                for i, segment in enumerate(result["segments"]):
                    if segment and isinstance(
                        segment, dict
                    ):  # ç¢ºä¿ segment ä¸æ˜¯ None ä¸”æ˜¯å­—å…¸
                        segments.append(
                            SegmentInfo(
                                id=i,
                                start=float(segment.get("start", 0)),
                                end=float(segment.get("end", 0)),
                                text=segment.get("text", "").strip(),
                            )
                        )
                processed["segments"] = segments

            # è™•ç†å–®è©è³‡è¨Š
            if TimestampGranularity.WORD in granularities_set and result.get("words"):
                words = []
                for word_data in result.get("words", []):
                    if word_data and isinstance(
                        word_data, dict
                    ):  # ç¢ºä¿ word_data ä¸æ˜¯ None ä¸”æ˜¯å­—å…¸
                        words.append(
                            WordInfo(
                                word=word_data.get("word", ""),
                                start=float(word_data.get("start", 0)),
                                end=float(word_data.get("end", 0)),
                            )
                        )
                processed["words"] = words
            else:
                # å¦‚æœæ²’æœ‰è«‹æ±‚ words æˆ–æ²’æœ‰ words è³‡æ–™ï¼Œè¨­ç‚ºç©ºé™£åˆ—
                processed["words"] = []

            logger.debug(
                f"è™•ç†è½‰éŒ„çµæœå®Œæˆ: text_length={len(processed['text'])}, segments_count={len(processed['segments'])}, words_count={len(processed['words'])}"
            )

            return processed

        except Exception as e:
            logger.error(f"è™•ç†è½‰éŒ„çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
            # è¿”å›åŸºæœ¬çš„çµæœï¼Œç¢ºä¿ä¸æœƒå› ç‚ºè™•ç†éŒ¯èª¤è€Œå®Œå…¨å¤±æ•—
            return {
                "text": result.get("text", "").strip(),
                "language": result.get("language", "unknown"),
                "segments": [],
                "words": [],
            }

    def _update_stats(
        self, processing_time: float, audio_duration: float, success: bool = True
    ) -> None:
        """æ›´æ–°çµ±è¨ˆè³‡è¨Š"""
        if success:
            self._stats["total_transcriptions"] += 1
            self._stats["total_processing_time"] += processing_time
            self._stats["total_audio_duration"] += audio_duration
        else:
            self._stats["failed_transcriptions"] += 1

    def get_stats(self) -> Dict[str, Any]:
        """ç²å–æœå‹™çµ±è¨ˆè³‡è¨Š"""
        total_transcriptions = self._stats["total_transcriptions"]

        stats = dict(self._stats)

        if total_transcriptions > 0:
            stats["avg_processing_time"] = (
                self._stats["total_processing_time"] / total_transcriptions
            )
            stats["avg_audio_duration"] = (
                self._stats["total_audio_duration"] / total_transcriptions
            )
            stats["avg_speed_ratio"] = (
                self._stats["total_audio_duration"]
                / self._stats["total_processing_time"]
                if self._stats["total_processing_time"] > 0
                else 0
            )
            stats["success_rate"] = total_transcriptions / (
                total_transcriptions + self._stats["failed_transcriptions"]
            )
        else:
            stats.update(
                {
                    "avg_processing_time": 0,
                    "avg_audio_duration": 0,
                    "avg_speed_ratio": 0,
                    "success_rate": 1.0,
                }
            )

        return stats

    async def shutdown(self) -> None:
        """é—œé–‰è½‰éŒ„æœå‹™ï¼Œæ¸…ç†è³‡æº"""
        logger.info("æ­£åœ¨é—œé–‰è½‰éŒ„æœå‹™...")

        # é—œé–‰åŸ·è¡Œç·’æ± 
        self._audio_executor.shutdown(wait=True)
        self._transcription_executor.shutdown(wait=True)

        logger.info("è½‰éŒ„æœå‹™å·²é—œé–‰")


# å…¨åŸŸè½‰éŒ„æœå‹™å¯¦ä¾‹
_transcription_service_instance: Optional[TranscriptionService] = None


def get_transcription_service() -> TranscriptionService:
    """
    ç²å–å…¨åŸŸè½‰éŒ„æœå‹™å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰

    Returns:
        TranscriptionService: è½‰éŒ„æœå‹™å¯¦ä¾‹
    """
    global _transcription_service_instance

    if _transcription_service_instance is None:
        _transcription_service_instance = TranscriptionService()

    return _transcription_service_instance


# å…¨åŸŸå¯¦ä¾‹
transcription_service = get_transcription_service()


# ä¾¿åˆ©å‡½æ•¸


async def transcribe_audio_file(
    audio_data: bytes, model_name: str, **kwargs
) -> TranscriptionResponse:
    """ä¾¿åˆ©å‡½æ•¸ï¼šè½‰éŒ„éŸ³æª”"""
    return await transcription_service.transcribe_audio(
        audio_data, model_name, **kwargs
    )


def get_transcription_stats() -> Dict[str, Any]:
    """ä¾¿åˆ©å‡½æ•¸ï¼šç²å–è½‰éŒ„çµ±è¨ˆ"""
    return transcription_service.get_stats()
