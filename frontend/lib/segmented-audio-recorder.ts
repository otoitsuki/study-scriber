"use client"

import { getAudioChunkIntervalMs } from './config'

// éŸ³è¨ŠéŒ„è£½ç‹€æ…‹
export type SegmentedAudioRecorderState = 'idle' | 'recording' | 'paused' | 'error'

// éŸ³è¨ŠéŒ„è£½é…ç½®
export interface SegmentedAudioRecorderConfig {
    segmentDuration: number // æ¯å€‹æ®µè½æ™‚é•·ï¼ˆæ¯«ç§’ï¼‰
    mimeType: string // éŸ³è¨Šæ ¼å¼
    audioBitsPerSecond?: number // éŸ³è¨Šä½å…ƒç‡
}

// éŸ³è¨Šæ®µè½è³‡æ–™
export interface AudioSegment {
    blob: Blob
    timestamp: number
    duration: number
    sequence: number
}

// é è¨­é…ç½®
const DEFAULT_CONFIG: SegmentedAudioRecorderConfig = {
    segmentDuration: 10000, // 10 ç§’åˆ‡ç‰‡ï¼ˆçµ±ä¸€é…ç½®ï¼‰
    mimeType: 'audio/webm;codecs=opus',
    audioBitsPerSecond: 64000, // 64 kbps for 10s chunksï¼ˆé™ä½ä½å…ƒç‡ï¼‰
}

/**
 * SegmentedAudioRecorder - åˆ†æ®µå¼éŸ³è¨ŠéŒ„è£½å™¨
 *
 * æ ¸å¿ƒç‰¹é»ï¼š
 * - ä½¿ç”¨éè¿´å•Ÿå‹•/åœæ­¢ MediaRecorder æ¨¡å¼
 * - æ¯å€‹ segment åŒ…å«å®Œæ•´ WebM Header
 * - æ”¯æ´å¯é…ç½®çš„åˆ‡ç‰‡æ™‚é•·ï¼ˆé è¨­ 5 ç§’ï¼‰
 * - è§£æ±º Azure OpenAI Whisper API æª”é ­å•é¡Œ
 */
export class SegmentedAudioRecorder {
    private stream: MediaStream | null = null
    private config: SegmentedAudioRecorderConfig
    private state: SegmentedAudioRecorderState = 'idle'
    private sequence: number = 0
    private recording = false
    private segmentTimeout: NodeJS.Timeout | null = null

    // äº‹ä»¶å›èª¿
    private onSegmentCallback?: (segment: AudioSegment) => void
    private onStateChangeCallback?: (state: SegmentedAudioRecorderState) => void
    private onErrorCallback?: (error: Error) => void

    constructor(config: Partial<SegmentedAudioRecorderConfig> = {}) {
        this.config = { ...DEFAULT_CONFIG, ...config }
    }

    /**
     * åˆå§‹åŒ–éŒ„éŸ³å™¨ - ç²å–éŸ³è¨Šæ¬Šé™
     */
    async initialize(): Promise<void> {
        if (this.stream) {
            return // å·²åˆå§‹åŒ–
        }

        try {
            this.stream = await navigator.mediaDevices.getUserMedia({ audio: true })
            console.log('ğŸ¤ [SegmentedAudioRecorder] éŸ³è¨Šæ¬Šé™ç²å–æˆåŠŸ')
        } catch (error) {
            const errorMsg = error instanceof Error ? error.message : 'ç²å–éŸ³è¨Šæ¬Šé™å¤±æ•—'
            this.handleError(new Error(errorMsg))
            throw error
        }
    }

    /**
     * é–‹å§‹éŒ„éŸ³ - å•Ÿå‹•éè¿´åˆ†æ®µéŒ„éŸ³
     */
    async start(onSegmentAvailable: (segment: AudioSegment) => void): Promise<void> {
        if (this.recording) {
            throw new Error('éŒ„è£½å·²åœ¨é€²è¡Œä¸­')
        }

        if (!this.stream) {
            await this.initialize()
        }

        this.onSegmentCallback = onSegmentAvailable
        this.recording = true
        this.sequence = 0

        console.log('ğŸ¬ [SegmentedAudioRecorder] é–‹å§‹åˆ†æ®µéŒ„éŸ³', {
            segmentDuration: this.config.segmentDuration,
            mimeType: this.config.mimeType,
            audioBitsPerSecond: this.config.audioBitsPerSecond
        })

        this.setState('recording')
        this.startSegment()
    }

    /**
     * æ ¸å¿ƒéè¿´å‡½å¼ - å•Ÿå‹•å–®å€‹éŒ„éŸ³æ®µè½
     */
    private startSegment(): void {
        if (!this.recording || !this.stream) {
            return
        }

        console.log(`ğŸµ [SegmentedAudioRecorder] é–‹å§‹éŒ„éŸ³æ®µè½ #${this.sequence}`)

        // å»ºç«‹æ–°çš„ MediaRecorder å¯¦ä¾‹
        const mediaRecorder = new MediaRecorder(this.stream, {
            mimeType: this.config.mimeType,
            audioBitsPerSecond: this.config.audioBitsPerSecond,
        })

        // è¨­å®šè³‡æ–™æ¥æ”¶è™•ç†
        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                console.log(`ğŸ“¦ [SegmentedAudioRecorder] æ®µè½ #${this.sequence} å®Œæˆ`, {
                    size: event.data.size,
                    mimeType: this.config.mimeType,
                    containsCompleteHeader: true // æ¯å€‹æ®µè½éƒ½æœ‰å®Œæ•´æª”é ­
                })

                const segment: AudioSegment = {
                    blob: event.data,
                    timestamp: Date.now(),
                    duration: this.config.segmentDuration,
                    sequence: this.sequence++,
                }

                // å›èª¿é€šçŸ¥æœ‰æ–°æ®µè½å¯ç”¨
                this.onSegmentCallback?.(segment)
            }
        }

        // éŒ¯èª¤è™•ç†
        mediaRecorder.onerror = (event) => {
            console.error(`âŒ [SegmentedAudioRecorder] æ®µè½ #${this.sequence} éŒ¯èª¤:`, event)
            this.handleError(new Error(`MediaRecorder éŒ¯èª¤: ${event}`))
        }

        // é–‹å§‹éŒ„è£½æ­¤æ®µè½
        mediaRecorder.start()

        // è¨­å®šè¨ˆæ™‚å™¨ï¼Œåœ¨æŒ‡å®šæ™‚é–“å¾ŒçµæŸæ­¤æ®µè½ä¸¦é–‹å§‹ä¸‹ä¸€æ®µ
        this.segmentTimeout = setTimeout(() => {
            if (mediaRecorder.state === 'recording') {
                // è«‹æ±‚æ•¸æ“šä¸¦åœæ­¢ MediaRecorder
                mediaRecorder.requestData() // è§¸ç™¼ ondataavailable
                mediaRecorder.stop()        // çµæŸæ­¤æ®µ

                // å¦‚æœä»åœ¨éŒ„éŸ³ç‹€æ…‹ï¼Œéè¿´é–‹å§‹ä¸‹ä¸€æ®µ
                if (this.recording) {
                    // çŸ­æš«å»¶é²ç¢ºä¿å‰ä¸€æ®µå®Œå…¨çµæŸ
                    setTimeout(() => {
                        this.startSegment()
                    }, 50)
                }
            }
        }, this.config.segmentDuration)
    }

    /**
     * åœæ­¢éŒ„éŸ³
     */
    stop(): void {
        console.log('â¹ï¸ [SegmentedAudioRecorder] åœæ­¢éŒ„éŸ³')

        this.recording = false

        // æ¸…é™¤è¨ˆæ™‚å™¨
        if (this.segmentTimeout) {
            clearTimeout(this.segmentTimeout)
            this.segmentTimeout = null
        }

        this.setState('idle')
    }

    /**
     * æ¸…ç†è³‡æº
     */
    cleanup(): void {
        this.stop()

        if (this.stream) {
            this.stream.getTracks().forEach(track => track.stop())
            this.stream = null
        }

        this.sequence = 0
        console.log('ğŸ§¹ SegmentedAudioRecorder å·²æ¸…ç†')
    }

    /**
     * æª¢æŸ¥æ˜¯å¦æ­£åœ¨éŒ„éŸ³
     */
    get isRecording(): boolean {
        return this.recording
    }

    /**
     * ç²å–ç•¶å‰åºè™Ÿ
     */
    get currentSequence(): number {
        return this.sequence
    }

    /**
     * ç²å–ç•¶å‰ç‹€æ…‹
     */
    get currentState(): SegmentedAudioRecorderState {
        return this.state
    }

    /**
     * ç²å–ç•¶å‰é…ç½®
     */
    get currentConfig(): SegmentedAudioRecorderConfig {
        return { ...this.config }
    }

    // è¨­å®šç‹€æ…‹
    private setState(newState: SegmentedAudioRecorderState): void {
        this.state = newState
        this.onStateChangeCallback?.(newState)
    }

    // éŒ¯èª¤è™•ç†
    private handleError(error: Error): void {
        console.error('âŒ SegmentedAudioRecorder éŒ¯èª¤:', error)
        this.setState('error')
        this.recording = false
        this.onErrorCallback?.(error)
    }

    // äº‹ä»¶å›èª¿è¨­å®š
    onSegment(callback: (segment: AudioSegment) => void): void {
        this.onSegmentCallback = callback
    }

    onStateChange(callback: (state: SegmentedAudioRecorderState) => void): void {
        this.onStateChangeCallback = callback
    }

    onError(callback: (error: Error) => void): void {
        this.onErrorCallback = callback
    }
}

// å·¥å» å‡½æ•¸
export const createSegmentedAudioRecorder = (config?: Partial<SegmentedAudioRecorderConfig>): SegmentedAudioRecorder => {
    return new SegmentedAudioRecorder(config)
}

/**
 * æª¢æŸ¥ç€è¦½å™¨åˆ†æ®µå¼éŸ³è¨ŠéŒ„è£½æ”¯æ´
 */
export async function checkSegmentedAudioRecordingSupport(): Promise<{ isSupported: boolean; error?: string }> {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        return { isSupported: false, error: 'ç€è¦½å™¨ä¸æ”¯æ´ MediaDevices API' }
    }

    if (!window.MediaRecorder) {
        return { isSupported: false, error: 'ç€è¦½å™¨ä¸æ”¯æ´ MediaRecorder API' }
    }

    // æª¢æŸ¥ MIME é¡å‹æ”¯æ´
    if (!MediaRecorder.isTypeSupported(DEFAULT_CONFIG.mimeType)) {
        return { isSupported: false, error: `ä¸æ”¯æ´éŸ³è¨Šæ ¼å¼: ${DEFAULT_CONFIG.mimeType}` }
    }

    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
        // ç«‹å³åœæ­¢ä¸²æµä»¥é‡‹æ”¾è³‡æº
        stream.getTracks().forEach(track => track.stop())
        return { isSupported: true }
    } catch (error) {
        return { isSupported: false, error: `ç„¡æ³•ç²å–éº¥å…‹é¢¨æ¬Šé™: ${error}` }
    }
}
